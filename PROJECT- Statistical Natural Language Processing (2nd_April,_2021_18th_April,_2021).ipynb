{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PROJECT - (2nd April, 2021 - 18th April, 2021)",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhRCbehPVJFW"
      },
      "source": [
        "# **PROJECT - (2nd April, 2021 - 18th April, 2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwuFabG6jejc"
      },
      "source": [
        "# **1. PART ONE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NoePY_7Yuso",
        "outputId": "8afcb401-d68a-4784-c84d-28c2ce3ebfbe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "piYyxeRwRP8S",
        "outputId": "b51fe5c8-d4f2-459b-f76a-25c433685edc"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdcU0PmbRYIe"
      },
      "source": [
        "project_path = '/content/drive/MyDrive/My Files/AIML Workbooks'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rks4fCIR7kY"
      },
      "source": [
        "import os                   # Importing os library\n",
        "import pandas as pd         # To read the data set\n",
        "import numpy as np          # Importing numpy library\n",
        "import seaborn as sns       # For data visualization\n",
        "import matplotlib.pyplot as plt      # Necessary library for plotting graphs\n",
        "from glob import glob       # Importing necessary library\n",
        "import tensorflow as tf     # Importing library\n",
        "%matplotlib inline\n",
        "sns.set(color_codes = True)\n",
        "\n",
        "from sklearn import metrics          # Importing metrics\n",
        "from sklearn.model_selection import train_test_split       # Splitting data into train and test set\n",
        "from sklearn.metrics import classification_report, accuracy_score, recall_score, f1_score, roc_auc_score, precision_score, confusion_matrix, average_precision_score\n",
        "from sklearn.preprocessing import StandardScaler           # Importing to standardize the data\n",
        "from sklearn.impute import SimpleImputer                   # Importing to fill in zero values in the data\n",
        "from sklearn.preprocessing import LabelEncoder  \n",
        "from sklearn.preprocessing import PolynomialFeatures       # Importing polynomial features library\n",
        "from sklearn.decomposition import PCA           # Importing to run pca analysis on data\n",
        "from sklearn import svm              # Importing necessary library for model building\n",
        "from sklearn.ensemble import RandomForestClassifier        # Importing necessary library for model building\n",
        "from sklearn.neighbors import KNeighborsClassifier         # Importing necessary library for model building  \n",
        "from sklearn import preprocessing               # Importing preprocessing library \n",
        "\n",
        "from sklearn.model_selection import KFold, cross_val_score           # Importing kfold for cross validation\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV           # Importing for hypertuning model\n",
        "from sklearn.cluster import KMeans              # For KMeans cluster model building\n",
        "from scipy.stats import zscore       # Import zscore library\n",
        "from scipy.spatial.distance import cdist        # Importing cdist functionality for elbow graph\n",
        "import tensorflow           # Importing tensorflow library\n",
        "from tensorflow.keras.models import Sequential, Model               # Importing tensorflow library\n",
        "from tensorflow.keras.utils import to_categorical          # Importing tensorflow library\n",
        "from tensorflow.keras import optimizers                    # Importing optimizers\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization, MaxPooling2D, Conv2D, Flatten, ZeroPadding2D, UpSampling2D, Reshape, SpatialDropout2D, Concatenate      # Importing necessary libraries \n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input           # Importing for model building\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau            # Importing for model building \n",
        "from tensorflow.keras.applications.mobilenet import MobileNet       # Importing for model building \n",
        "from tensorflow.keras.losses import binary_crossentropy             # Importing for model building\n",
        "from tensorflow.keras.backend import log, epsilon          # Importing necessary library for model building \n",
        "from keras.utils import np_utils     # Importing necessary library\n",
        "from sklearn import svm              # Importing necessary library for model building\n",
        "from sklearn.svm import SVC          # Import svc library for model building\n",
        "\n",
        "from skimage.color import rgb2gray              # Loading color library\n",
        "from sklearn.preprocessing import OneHotEncoder            # Library for one hot encoding\n",
        "from sklearn.metrics import confusion_matrix               # Loading necessary library\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array            # Loading image generator \n",
        "from keras.preprocessing import image           # Importing necessary image library\n",
        "from tensorflow import keras         # Loading keras libaray \n",
        "from tensorflow.keras.optimizers import Adam, SGD          # Importing optimizer library\n",
        "import cv2                  # Importing necessary library\n",
        "from PIL import ImageFile            # Importing image library\n",
        "from tqdm import tqdm                # Importing necessary library\n",
        "import time                 # Importing time library\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid              # Importing necessary image library\n",
        "from PIL import Image       # Importing image library\n",
        "\n",
        "import re                   # Importing regular expression library \n",
        "import nltk                 # Import necessary library \n",
        "from nltk.corpus import stopwords               # Importing necessary library \n",
        "from sklearn.feature_extraction.text import CountVectorizer          # Importing count library \n",
        "from sklearn.preprocessing import MultiLabelBinarizer      # Imorting necessary library "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bAJujaWaqI2",
        "outputId": "cf838d95-f61a-46f7-e266-41ea850f2fc1"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ExL2odeVB6t"
      },
      "source": [
        "## **1. Import and analyse the data set.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp5UHx0ySBc_"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/My Files/AIML Workbooks/blogtext.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtEMEh85Tnq0",
        "outputId": "4b791f30-2f6f-4d41-d48f-19777306118f"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(681284, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APMFG01gUlPB",
        "outputId": "a8b27f61-d32e-49d6-b7c3-48dba7ba237a"
      },
      "source": [
        "df.size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4768988"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "OA6hkkRQUmE_",
        "outputId": "8f126c3a-739c-48d1-f8ff-d97f515cece0"
      },
      "source": [
        "df.sample(10)         # Checking if the dataset is loaded properly"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>topic</th>\n",
              "      <th>sign</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>613968</th>\n",
              "      <td>3568208</td>\n",
              "      <td>female</td>\n",
              "      <td>14</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>08,July,2004</td>\n",
              "      <td>sigh soooo sad skool just sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61224</th>\n",
              "      <td>3881543</td>\n",
              "      <td>male</td>\n",
              "      <td>24</td>\n",
              "      <td>Military</td>\n",
              "      <td>Gemini</td>\n",
              "      <td>14,July,2004</td>\n",
              "      <td>I had a terrible dream yesterday. W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6601</th>\n",
              "      <td>883178</td>\n",
              "      <td>male</td>\n",
              "      <td>36</td>\n",
              "      <td>Fashion</td>\n",
              "      <td>Aries</td>\n",
              "      <td>13,November,2002</td>\n",
              "      <td>As some of you know, my girlfriend ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486646</th>\n",
              "      <td>4164598</td>\n",
              "      <td>male</td>\n",
              "      <td>16</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Scorpio</td>\n",
              "      <td>12,August,2004</td>\n",
              "      <td>Today is the first time in c math lec.. it ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234953</th>\n",
              "      <td>1021779</td>\n",
              "      <td>female</td>\n",
              "      <td>25</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Scorpio</td>\n",
              "      <td>29,January,2004</td>\n",
              "      <td>Getting back to my trip play-by-play, here'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378654</th>\n",
              "      <td>2268074</td>\n",
              "      <td>male</td>\n",
              "      <td>47</td>\n",
              "      <td>BusinessServices</td>\n",
              "      <td>Leo</td>\n",
              "      <td>24,February,2004</td>\n",
              "      <td>urlLink Banned Books Week      Tohti Tunya...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415384</th>\n",
              "      <td>3744749</td>\n",
              "      <td>male</td>\n",
              "      <td>17</td>\n",
              "      <td>Student</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>12,July,2004</td>\n",
              "      <td>Noize:'Intergalactic Planetary' Beastie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198090</th>\n",
              "      <td>1472995</td>\n",
              "      <td>female</td>\n",
              "      <td>27</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Aries</td>\n",
              "      <td>11,September,2003</td>\n",
              "      <td>Dear Ndugu  -  Wow...amazing what...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446141</th>\n",
              "      <td>3857809</td>\n",
              "      <td>male</td>\n",
              "      <td>25</td>\n",
              "      <td>Government</td>\n",
              "      <td>Gemini</td>\n",
              "      <td>03,August,2004</td>\n",
              "      <td>Well, our first page was posted.   urlL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396721</th>\n",
              "      <td>3546623</td>\n",
              "      <td>female</td>\n",
              "      <td>42</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Libra</td>\n",
              "      <td>04,June,2004</td>\n",
              "      <td>With in and With out  Dark and  gloomy, Onc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ...                                               text\n",
              "613968  3568208  ...                   sigh soooo sad skool just sta...\n",
              "61224   3881543  ...             I had a terrible dream yesterday. W...\n",
              "6601     883178  ...             As some of you know, my girlfriend ...\n",
              "486646  4164598  ...     Today is the first time in c math lec.. it ...\n",
              "234953  1021779  ...     Getting back to my trip play-by-play, here'...\n",
              "378654  2268074  ...      urlLink Banned Books Week      Tohti Tunya...\n",
              "415384  3744749  ...         Noize:'Intergalactic Planetary' Beastie...\n",
              "198090  1472995  ...               Dear Ndugu  -  Wow...amazing what...\n",
              "446141  3857809  ...         Well, our first page was posted.   urlL...\n",
              "396721  3546623  ...     With in and With out  Dark and  gloomy, Onc...\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSkr6JeKWKFs",
        "outputId": "2bf25f60-c61a-41e3-9174-d563e45625d9"
      },
      "source": [
        "df.isna().any()          # Checking for any null values in the dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id        False\n",
              "gender    False\n",
              "age       False\n",
              "topic     False\n",
              "sign      False\n",
              "date      False\n",
              "text      False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaPJP9HRWlGL",
        "outputId": "3f04f3e8-a78c-4940-8630-e44150b93263"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id        0\n",
              "gender    0\n",
              "age       0\n",
              "topic     0\n",
              "sign      0\n",
              "date      0\n",
              "text      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5YcE2MRWMsc",
        "outputId": "59fadab6-bf0b-4ae9-9d28-383a1bc267c1"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 681284 entries, 0 to 681283\n",
            "Data columns (total 7 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   id      681284 non-null  int64 \n",
            " 1   gender  681284 non-null  object\n",
            " 2   age     681284 non-null  int64 \n",
            " 3   topic   681284 non-null  object\n",
            " 4   sign    681284 non-null  object\n",
            " 5   date    681284 non-null  object\n",
            " 6   text    681284 non-null  object\n",
            "dtypes: int64(2), object(5)\n",
            "memory usage: 36.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9iRpWxzWe2j",
        "outputId": "7cf91de0-8584-4bb2-df9c-9c2cd7ab7fbf"
      },
      "source": [
        "df.gender.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "male      345193\n",
              "female    336091\n",
              "Name: gender, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt8pS4W-aeSo"
      },
      "source": [
        "# As the dataset is large we are using fewer rows, inorder to run compatibly with the machine so as to avoid crashing (100000)\n",
        "\n",
        "df_new = pd.read_csv('/content/drive/MyDrive/My Files/AIML Workbooks/blogtext.csv', nrows = 100000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "l6FA4BTCa4-i",
        "outputId": "51775681-dd44-4384-ccd9-061cab906d15"
      },
      "source": [
        "df_new.sample(10)         # Checking if the dataset is loaded properly"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>topic</th>\n",
              "      <th>sign</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>67380</th>\n",
              "      <td>2134154</td>\n",
              "      <td>male</td>\n",
              "      <td>16</td>\n",
              "      <td>Arts</td>\n",
              "      <td>Taurus</td>\n",
              "      <td>19,April,2004</td>\n",
              "      <td>If you are not already watching Alias a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23519</th>\n",
              "      <td>299143</td>\n",
              "      <td>female</td>\n",
              "      <td>23</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>Cancer</td>\n",
              "      <td>07,June,2002</td>\n",
              "      <td>Hmm...archives aren't working...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61108</th>\n",
              "      <td>3423289</td>\n",
              "      <td>female</td>\n",
              "      <td>23</td>\n",
              "      <td>Arts</td>\n",
              "      <td>Leo</td>\n",
              "      <td>28,May,2004</td>\n",
              "      <td>Here is  part of a nice email...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73668</th>\n",
              "      <td>1570719</td>\n",
              "      <td>male</td>\n",
              "      <td>26</td>\n",
              "      <td>Education</td>\n",
              "      <td>Libra</td>\n",
              "      <td>01,August,2004</td>\n",
              "      <td>God I hope this doesn’t come out ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54874</th>\n",
              "      <td>3712172</td>\n",
              "      <td>male</td>\n",
              "      <td>17</td>\n",
              "      <td>Student</td>\n",
              "      <td>Pisces</td>\n",
              "      <td>23,June,2004</td>\n",
              "      <td>Hey everybody!   Got to bed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94796</th>\n",
              "      <td>3492238</td>\n",
              "      <td>female</td>\n",
              "      <td>17</td>\n",
              "      <td>Student</td>\n",
              "      <td>Aries</td>\n",
              "      <td>11,June,2004</td>\n",
              "      <td>1. Don't drink grape juice while we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87530</th>\n",
              "      <td>171019</td>\n",
              "      <td>female</td>\n",
              "      <td>23</td>\n",
              "      <td>Education</td>\n",
              "      <td>Leo</td>\n",
              "      <td>21,January,2004</td>\n",
              "      <td>damn it...  AT&amp;T turned off my cell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19172</th>\n",
              "      <td>2565326</td>\n",
              "      <td>male</td>\n",
              "      <td>48</td>\n",
              "      <td>Communications-Media</td>\n",
              "      <td>Aries</td>\n",
              "      <td>05,May,2004</td>\n",
              "      <td>urlLink    Nice day..&amp;nbsp; urlLink</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26187</th>\n",
              "      <td>1939766</td>\n",
              "      <td>female</td>\n",
              "      <td>23</td>\n",
              "      <td>Arts</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>12,August,2004</td>\n",
              "      <td>I haven't been watching Cribs lat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4463</th>\n",
              "      <td>766556</td>\n",
              "      <td>female</td>\n",
              "      <td>34</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Sagittarius</td>\n",
              "      <td>02,July,2003</td>\n",
              "      <td>Worst comb-over ever  Last night I saw...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  ...                                               text\n",
              "67380  2134154  ...         If you are not already watching Alias a...\n",
              "23519   299143  ...                   Hmm...archives aren't working...\n",
              "61108  3423289  ...                   Here is  part of a nice email...\n",
              "73668  1570719  ...               God I hope this doesn’t come out ...\n",
              "54874  3712172  ...                    Hey everybody!   Got to bed ...\n",
              "94796  3492238  ...             1. Don't drink grape juice while we...\n",
              "87530   171019  ...             damn it...  AT&T turned off my cell...\n",
              "19172  2565326  ...            urlLink    Nice day..&nbsp; urlLink    \n",
              "26187  1939766  ...               I haven't been watching Cribs lat...\n",
              "4463    766556  ...          Worst comb-over ever  Last night I saw...\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W8X6LIGcMda",
        "outputId": "0650746e-ceea-4a63-ac5d-4575700283c8"
      },
      "source": [
        "df_new.size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "700000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lD_EI44cOUl",
        "outputId": "1b9111be-d26e-4798-bd3d-a225be17dbf7"
      },
      "source": [
        "df_new.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67OkFz3Ha4tB",
        "outputId": "00988ce2-c607-40a1-e38d-4ac3d6da2f17"
      },
      "source": [
        "df_new.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 7 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   id      100000 non-null  int64 \n",
            " 1   gender  100000 non-null  object\n",
            " 2   age     100000 non-null  int64 \n",
            " 3   topic   100000 non-null  object\n",
            " 4   sign    100000 non-null  object\n",
            " 5   date    100000 non-null  object\n",
            " 6   text    100000 non-null  object\n",
            "dtypes: int64(2), object(5)\n",
            "memory usage: 5.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNXMbUhJa4bh",
        "outputId": "e7feca5c-43d4-4147-9105-889b49aea711"
      },
      "source": [
        "df_new.gender.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "male      53358\n",
              "female    46642\n",
              "Name: gender, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "Xwu-v_d_XEED",
        "outputId": "8ece2796-bef1-48cd-fb72-dcca2a6559fd"
      },
      "source": [
        "sns.countplot(x = 'gender', data = df_new)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb1e47b0210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "zquIc9y8XS-z",
        "outputId": "cb17b808-4dad-4784-a2c2-f0a7bcda60d0"
      },
      "source": [
        "plt.figure(figsize = (12,6))\n",
        "sns.countplot(x = 'sign', data = df_new);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAukAAAF5CAYAAAAiSrTVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXRUVb728adSGYCEEIIEAqIiGgSRCxLBCRBQwxACKBIuja3iyG1aRJQE0DDIlIDaGMGpaVm3taUVUUxA45VoO4EjNA0oSASkIRBIGBJCpqr9/sFLNYEEMlI74ftZi7Wos09V/fY+p+o87NpVOIwxRgAAAACs4ePtAgAAAACURkgHAAAALENIBwAAACxDSAcAAAAsQ0gHAAAALENIBwAAACxDSAcAAAAs4+vtAmx16NAxud38hDwAAABqno+PQ02bBpbbTkgvh9ttCOkAAADwCpa7AAAAAJYhpAMAAACWIaQDAAAAliGkAwAAAJYhpAMAAACWIaQDAAAAliGkAwAAAJYhpAMAAACWIaQDAAAAliGkAwAAAJYhpAMAAACWIaQDAAAAliGkAwAAAJbx9XYBwPkQ0sRffv4B3i6jUoqLCnX4SJG3ywAAAF5ASMcFwc8/QGlLBnq7jEqJun+1JEI6AAAXIpa7AAAAAJYhpAMAAACWIaQDAAAAliGkAwAAAJYhpAMAAACWIaQDAAAAliGkAwAAAJYhpAMAAACWIaQDAAAAliGkAwAAAJYhpAMAAACWIaQDAAAAljkvIT0xMVF9+/ZV+/bttW3bNs/2HTt2KDY2VlFRUYqNjdXOnTtrtQ0AAACoC85LSO/Xr5/efPNNtW7dutT2adOmadSoUUpLS9OoUaOUkJBQq20AAABAXXBeQnpkZKTCw8NLbcvOztaWLVsUHR0tSYqOjtaWLVuUk5NTK20AAABAXeHrrSfOzMxUixYt5HQ6JUlOp1NhYWHKzMyUMabG20JDQ73TUQAAAKCSvBbSbdesWZC3SwDUvHljb5cAAAC8wGshPTw8XPv375fL5ZLT6ZTL5VJWVpbCw8NljKnxtsrKzs6T221qoefwhroadg8cyPV2CQAAoBb4+DjOOinstZ9gbNasmTp06KDU1FRJUmpqqjp06KDQ0NBaaQMAAADqCocxptani2fNmqWPP/5YBw8eVNOmTRUSEqJVq1YpIyND8fHxOnr0qIKDg5WYmKjLL79ckmqlrTKYSa9fmjdvrLQlA71dRqVE3b+amXQAAOqpc82kn5eQXhcR0usXQjoAALCJtctdAAAAAJSNkA4AAABYhpAOAAAAWIaQDgAAAFiGkA4AAABYhpAOAAAAWIaQDgAAAFiGkA4AAABYhpAOAAAAWIaQDgAAAFiGkA4AAABYhpAOAAAAWIaQDgAAAFiGkA4AAABYhpAOAAAAWIaQDgAAAFiGkA4AAABYxtfbBQDAhaxxSAM18PPzdhmVUlBcrNzDBd4uAwDqNUI6AKsFh/grwC/A22VUSmFxoY4eLqrQvg38/DTovfm1XFHNWjXsSeWKkA4AtYmQDsBqAX4Buu+9/t4uo1JeH/aRpIqFdAAAysKadAAAAMAyhHQAAADAMoR0AAAAwDKsSYckKbSJv5z+devLea6iQuUcYd0vAACofwjpkCQ5/QP02wvDvV1GpVzy6HLx5TwAAFAfsdwFAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAM/5kRUA80CfGTv18Db5dRYUXFBTpyuNjbZQAAYC1COlAP+Ps10Ct/jfJ2GRX28N1pkgjpAACUh+UuAAAAgGUI6QAAAIBlCOkAAACAZViTDgAAUM+ENgmU079uzcW6itzKOXLM22VYg5AOAABQzzj9fbTzT/u8XUalXPZYS2+XYJW69U8sAAAA4AJASAcAAAAsQ0gHAAAALENIBwAAACxDSAcAAAAsQ0gHAAAALENIBwAAACzD76RXUGiTBnL6+3m7jEpxFRUr50iBt8sAAABAJRHSK8jp76cDL73h7TIqpfnY0ZII6QAAAHUNy10AAAAAy1gR0j/99FMNHTpUQ4YMUUxMjD7++GNJ0o4dOxQbG6uoqCjFxsZq586dnvtUtQ0AAACwnddDujFGkyZNUlJSklauXKmkpCTFxcXJ7XZr2rRpGjVqlNLS0jRq1CglJCR47lfVNgAAAMB2Xg/pkuTj46Pc3FxJUm5ursLCwnTo0CFt2bJF0dHRkqTo6Ght2bJFOTk5ys7OrlIbAAAAUBd4/YujDodDf/rTn/Q///M/atSokY4dO6ZXX31VmZmZatGihZxOpyTJ6XQqLCxMmZmZMsZUqS00NNRr/QQAAAAqyushvaSkRK+88ooWL16sbt266YcfftBjjz2mpKQkr9bVrFmQV5+/pjRv3tjbJdQq+ld31ee+SfQPAKqC95b/8HpI/+mnn5SVlaVu3bpJkrp166aGDRsqICBA+/fvl8vlktPplMvlUlZWlsLDw2WMqVJbZWRn58ntNp7bdfWkOXAgt0L70T871ef+1ee+SfQPgHfx3mI/Hx/HWSeFvb4mvWXLltq3b59+/fVXSVJGRoays7N16aWXqkOHDkpNTZUkpaamqkOHDgoNDVWzZs2q1AYAAADUBV6fSW/evLmmT5+u8ePHy+FwSJLmzJmjkJAQTZ8+XfHx8Vq8eLGCg4OVmJjouV9V2wAAAADbeT2kS1JMTIxiYmLO2N6uXTu98847Zd6nqm0AAACA7by+3AUAAABAaYR0AAAAwDKEdAAAAMAyhHQAAADAMoR0AAAAwDKEdAAAAMAyhHQAAADAMoR0AAAAwDJW/GdGAAAAQEWFNmkop3/dirGuohLlHDle4f3rVu8AAABwwXP6+2r/wrXeLqNSWoy/oVL7s9wFAAAAsAwhHQAAALAMIR0AAACwDGvSAQC1pnFIAzXw8/N2GZVSUFys3MMF3i4DwAWOkA4AqDUN/PwUvfxNb5dRKanDf6dcEdIBeBfLXQAAAADLENIBAAAAy7DcBQAAlCk4pJEC/JzeLqPCCotdOno439tlADWCkA4AAMoU4OfUo+/t9nYZFfbCsDbeLgGoMSx3AQAAACzDTDoAALjghIQEys+vbs1VFhe7dfjwMW+XgfOEkA4AAC44fn4++vDvB71dRqUMiL3I2yXgPCKkAwBQRY1DGqqBX926lBYUlyj38HFvlwHgHOrWOwsAABZp4OerocvXeLuMSnl/eD/lersIAOdUtxZjAQAAABcAQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZK0J6YWGhpk2bpttvv12DBw/W008/LUnasWOHYmNjFRUVpdjYWO3cudNzn6q2AQAAALarcEhfsmRJmdtff/31ahcxf/58BQQEKC0tTSkpKRo/frwkadq0aRo1apTS0tI0atQoJSQkeO5T1TYAAADAdhUO6YsWLSpz+0svvVStAo4dO6b3339f48ePl8PhkCRddNFFys7O1pYtWxQdHS1Jio6O1pYtW5STk1PlNgAAAKAu8D3XDmvXrpUkud1urVu3TsYYT9u///1vBQYGVquA3bt3KyQkRC+++KK++eYbBQYGavz48WrQoIFatGghp9MpSXI6nQoLC1NmZqaMMVVqCw0NrVatAAAAwPlwzpA+depUSSfWjU+ZMsWz3eFwqHnz5nrqqaeqVYDL5dLu3bvVsWNHxcXF6Z///KceeeQRLVy4sFqPW13NmgV59flrSvPmjb1dQq2if3VXfe6bRP/qOvpXd9Xnvkn0r66rTP/OGdLT09MlSZMmTVJSUlLVqypHeHi4fH19PctT/uu//ktNmzZVgwYNtH//frlcLjmdTrlcLmVlZSk8PFzGmCq1VUZ2dp7c7v98alBXT5oDB3IrtB/9s1N97l997ptE/06if3aqz/2rz32T6N9J9aF/Pj6Os04KV3hN+qkB3e12l/pTHaGhoerRo4e++uorSSd+mSU7O1uXXXaZOnTooNTUVElSamqqOnTooNDQUDVr1qxKbQAAAEBdcM6Z9JM2b96smTNnauvWrSosLJQkGWPkcDj0008/VauIGTNmaMqUKUpMTJSvr6+SkpIUHBys6dOnKz4+XosXL1ZwcLASExM996lqGwAAAGC7Cof0+Ph49enTR3PmzFGDBg1qtIg2bdror3/96xnb27Vrp3feeafM+1S1DQAAALBdhUP6nj17NGHCBM/PJAIAAACoHRVek37bbbfpyy+/rM1aAAAAAKgSM+mFhYUaN26cunXrposuuqhUW2386gsAAABwoapwSL/iiit0xRVX1GYtAAAAAFSJkD5u3LjarAMAAADA/1fhkL527dpy22644YYaKQYAAABAJUL61KlTS90+dOiQiouL1aJFC61Zs6bGCwMAAAAuVBUO6enp6aVuu1wuvfTSSwoMDKzxogAAAIALWYV/gvF0TqdTjzzyiP785z/XZD0AAADABa/KIV2SvvrqK/5zIwAAAKCGVXi5S+/evUsF8uPHj6uoqEjTpk2rlcIAAACAC1WFQ/r8+fNL3W7YsKHatm2roKCgGi8KAAAAuJBVOKR3795dkuR2u3Xw4EFddNFF8vGp1moZAAAAAGWocMrOy8vTpEmT1LlzZ/Xq1UudO3dWXFyccnNza7M+AAAA4IJT4ZA+a9YsHT9+XCkpKdq4caNSUlJ0/PhxzZo1qzbrAwAAAC44FV7u8sUXX+iTTz5Rw4YNJUlt27bV3Llzddttt9VacQAAAMCFqMIz6QEBAcrJySm17dChQ/L396/xogAAAIALWYVn0ocPH64xY8bo3nvvVatWrbR3714tXbpUd911V23WBwAAAFxwKhzSx44dqxYtWiglJUVZWVkKCwvTAw88QEgHAAAAaliFl7vMnj1bbdu21dKlS7V69WotXbpU7dq10+zZs2uzPgAAAOCCU+GQnpqaqk6dOpXa1qlTJ6WmptZ4UQAAAMCFrMIh3eFwyO12l9rmcrnO2AYAAACgeioc0iMjI7Vw4UJPKHe73UpOTlZkZGStFQcAAABciCr8xdGpU6fq4Ycf1s0336xWrVopMzNTzZs318svv1yb9QEAAAAXnAqH9JYtW+q9997Txo0blZmZqfDwcHXu3Fk+PhWejAcAAABQARUO6ZLk4+OjLl26qEuXLrVVDwAAAHDBYxocAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwjFUh/cUXX1T79u21bds2SdKGDRsUExOjqKgojRkzRtnZ2Z59q9oGAAAA2M6akL5582Zt2LBBrVu3liS53W49+eSTSkhIUFpamiIjI7VgwYJqtQEAAAB1gRUhvaioSDNnztT06dM92zZt2qSAgABFRkZKkkaOHKmPPvqoWm0AAABAXeDr7QIkaeHChYqJidHFF1/s2ZaZmalWrVp5boeGhsrtduvw4cNVbgsJCalwTc2aBVWzV3Zo3ryxt0uoVfSv7qrPfZPoX11H/+qu+tw3if7VdZXpn9dD+vr167Vp0yY98cQT3i6llOzsPLndxnO7rp40Bw7kVmg/+men+ty/+tw3if6dRP/sVJ/7V5/7JtG/k+pD/3x8HGedFPZ6SP/uu++UkZGhfv36SZL27dun+++/X3fffbf27t3r2S8nJ0c+Pj4KCQlReHh4ldoAAACAusDra9Ifeughffnll0pPT1d6erpatmypJUuW6IEHHlBBQYG+//57SdKyZcvUv39/SVKnTp2q1AYAAADUBV6fSS+Pj4+PkpKSNG3aNBUWFqp169aaP39+tdoAAACAusC6kJ6enu75+7XXXquUlJQy96tqGwAAAGA7ry93AQAAAFAaIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALAMIR0AAACwDCEdAAAAsAwhHQAAALCM10P6oUOH9OCDDyoqKkqDBw/WuHHjlJOTI0nasGGDYmJiFBUVpTFjxig7O9tzv6q2AQAAALbzekh3OBx64IEHlJaWppSUFLVp00YLFiyQ2+3Wk08+qYSEBKWlpSkyMlILFiyQpCq3AQAAAHWB10N6SEiIevTo4bndpUsX7d27V5s2bVJAQIAiIyMlSSNHjtRHH30kSVVuAwAAAOoCr4f0U7ndbr311lvq27evMjMz1apVK09baGio3G63Dh8+XOU2AAAAoC7w9XYBp3rmmWfUqFEjjR49Wv/3f//n1VqaNQvy6vPXlObNG3u7hFpF/+qu+tw3if7VdfSv7qrPfZPoX11Xmf5ZE9ITExO1a9cuvfzyy/Lx8VF4eLj27t3rac/JyZGPj49CQkKq3FYZ2dl5cruN53ZdPWkOHMit0H70z071uX/1uW8S/TuJ/tmpPvevPvdNon8n1Yf++fg4zjopbMVyl+eee06bNm3SokWL5O/vL0nq1KmTCgoK9P3330uSli1bpv79+1erDQAAAKgLvD6T/ssvv+iVV17RZZddppEjR0qSLr74Yi1atEhJSUmaNm2aCgsL1bp1a82fP1+S5OPjU6U2AAAAoC7weki/8sortXXr1jLbrr32WqWkpNRoGwAAAGA7K5a7AAAAAPgPQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGCZehvSd+zYodjYWEVFRSk2NlY7d+70dkkAAABAhdTbkD5t2jSNGjVKaWlpGjVqlBISErxdEgAAAFAh9TKkZ2dna8uWLYqOjpYkRUdHa8uWLcrJyfFyZQAAAMC5+Xq7gNqQmZmpFi1ayOl0SpKcTqfCwsKUmZmp0NDQCj2Gj4/jzG2NA2u0zvOhrH6Ux9m4eS1WUjsq078GQWG1WEntqEz/ggJb1GIlNa8yfWvWqG71Tapc/8IaBddiJbWjcv2r3++dYY0a1GIltaMy/Qtt5KzFSmpeZfrWsFHdm6usTP98g+vWsZMq1z+fxgG1WEntOLV/5+qrwxhjarug823Tpk2Ki4vTqlWrPNsGDhyo+fPn6+qrr/ZiZQAAAMC51b1/QlZAeHi49u/fL5fLJUlyuVzKyspSeHi4lysDAAAAzq1ehvRmzZqpQ4cOSk1NlSSlpqaqQ4cOFV7qAgAAAHhTvVzuIkkZGRmKj4/X0aNHFRwcrMTERF1++eXeLgsAAAA4p3ob0gEAAIC6ql4udwEAAADqMkI6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCei3r27evtm3b5u0yzunIkSPq3LmzZs2adV6f96233tLSpUvP63OeTUXH4cEHH9Rvv/12nqoqW3FxsRYuXKioqCgNHjxYQ4cO1bx581RcXFxjzzFkyBAVFBTU2OPVlOLiYiUnJysqKkqDBg1STEyMHn30UW3fvr3GnqOix3jq1Kn6/vvva+x5pfNzbGvahx9+qKFDh2rIkCHq37+/Jk6cWOXH+te//uW5/9GjR/Xaa6+Val+xYoV27NhR5cevrfO6JsegMrz9PlrWde7U18/dd9+tTz/91BulVdsDDzygt956q9Q2Y4z69eunu+++u8Zf+7Xtrrvu0pAhQzRw4EB17NhRQ4YM0ZAhQzR58mRvl1aj+vbtq/79+ysmJkbR0dFatWqVFi5cqNWrV3u7tMoxqFV9+vQxW7du9XYZ5/TGG2+Y0aNHm+uvv94UFhael+csLi4+L89TGecaB5fLZdxutxcqO9PEiRPNuHHjTG5urjHmxHguW7bM5OXlVfuxa+PY1ORjTpw40fzhD38wR44cMcYY43a7zaeffmo+/vjjGnsOb6rNY1sV5zp2+/fvNz169DB79+41xpw4Hps3b66R5969e7fp3r17qW2jR4826enplX6s2nzPqc0xsPG98lTnus5V9HjZ2M/Vq1ebu+66q9S2tWvXmltvvbXca4GN/ThdWa+rqrLpunjSqefk5s2bzTXXXGOys7O9XFXl+Xr7HwkXon/84x966aWXVFRUJD8/P02ePFldunSRJL366qv64IMPJEnXXHONnnrqKQUGBtZ6Te+++66efPJJvfLKK1qzZo0GDBig7du3a/LkycrPz1dERIT27NmjsWPHqk+fPurbt69efvllRURESFKp24mJifr2229VXFyspk2bas6cOWrdurX+/e9/684779Qdd9yhdevWacSIETp48KDy8/MVFxen5ORkz98llbr9ySefaOHChfLx8ZHL5dLTTz+tHj16nJdxSE5O1i+//KK8vDzt3btXf//73zVs2DBPf7OysjRr1izt3btXhYWFGjRokB555BG53W7NnDlT69atk7+/vxo1aqRly5bVSJ07d+7UJ598on/84x8KCgqSJPn6+io2NlZbt27VjBkzdPz4cRUWFmrEiBG69957JUnx8fHy9fXV9u3bdejQIV133XVKSEiQv7+/4uPj5XQ6tWPHDh07dkwrV65U+/bt9eOPPyowMFAZGRmaPXu2Dhw4IEkaM2aMhg0bpl27dikhIUE5OTny9fXVhAkT1KtXL0lS+/btNW7cOH322Wfq2bOn9u3bJ39/f+3cuVP79u1Tly5dlJiYKIfDUaW+BwcHS5IcDoduueUWSVJRUZGef/55fffddyoqKlL79u01ffp0BQYGKj4+3vP8u3fv1m233aY+ffooOTlZ+/bt0z333KN77rlHUulz+u6771anTp20YcMGZWVlacCAAXriiScknZglHDNmjPr06VPt43p6/yp7bMsb29zcXM2ZM0ebNm2Sw+FQZGSkEhISzjlWp58P5Tl48KB8fX0VEhLiOR4dO3aUJE2cOFE7duxQcXGxLrnkEs2ZM0dNmjSRJD3//PNavXq1QkJC1L17d61du1YrVqzQN998o8TERK1YsUIzZ85Ubm6uhgwZooYNG+quu+7Spk2bNGvWLP3pT39SXFycmjVrdtZxOdt5ferfJXlu+/j4KC4uTtu3b5evr6/atm2rhQsXVmkM1q9fr6SkJB07dkySNGnSJN18883auHGjZs+erfz8fDVq1EhTp05V586dy32vPPm6zcrK0pVXXqk5c+aocePGpd4rXS6XFixYoC+++EKS1LNnTz3xxBNyOp2VPher4/RrxNdff61FixbpyJEjGjBggB5//HFJJ14/V111lf75z3+qSZMmeumll/Twww/r0KFDKiwsVOfOnTVjxgz5+/uf1/pP6tevn6ZPn66MjAy1a9dO0olPcu644w79/ve/97z2yzrPyju/Je9d609XUlJS7nif7Zpc1nWxe/fuNfJaqmkdO3b0vKf16tVLo0ePLjdT7N+/X7NmzdLOnTslSdHR0Xr44YeVl5enuXPnauvWrSosLFSPHj00efJkOZ1Ovfjii0pNTVVAQIAcDof+93//13NtqjZv/yuhvjt9hmHXrl1mxIgRnhmybdu2md69extjjPnss8/MoEGDTG5urnG73ebJJ580SUlJtV7jTz/9ZPr06WPcbrdZuXKluf/++40xxgwbNsysWLHCGGPM+vXrzVVXXeWZDTm9X6fePvVfq2+//bZ57LHHjDEn/uUeERFhVq1a5Wl/4YUXzLx58874++m3Bw8ebH788UdjjDElJSWe8atJ5Y3DCy+8YHr37l2qX6f299577zXffvutMcaYwsJC89///d/myy+/NJs3bzb9+/c3LpfLGGPM4cOHa6zWVatWmZiYmDLbcnNzPZ8C5OXlmQEDBpjt27cbY4yJi4sz0dHRJi8vzxQXF5v77rvP/PWvf/W0DRs2zBw7dszzWBEREZ59b7/9drN69WpPW05OjjHGmOHDh5u3337bGGPML7/8Yrp37+4Zq4iICPPKK6947hMXF2dGjhxpCgoKTGFhoRk4cKD58ssva6zvxhizaNEis2jRIs/tpKQk89xzz5V6/sLCQpOfn2+uv/56Ex8fb1wul9m3b5/p0qWLZ7b61GM8evRoM378eONyuczRo0dN9+7dzY4dOzxtVZnVrUr/znVsyxvb+Ph4M3PmTM+5ePL4nHnX5LkAAA8bSURBVGusTj8fyuNyuczYsWNN9+7dzR//+Efz+uuve86PU183zz33nJk/f74xxpg1a9aYwYMHm2PHjhmXy2X+8Ic/mGHDhhljjFm3bp3n7xWZST/XuJR3Xp/+91Nvf/zxx2bMmDGe7ed6/ZY3BocOHTI33nij+eGHH4wxJ96/Dh8+bAoLC03v3r3N119/bYwx5quvvjK9e/c2hYWF5b5X3nTTTebAgQPGmBPHtKz3zjfffNPcc889prCw0BQWFprf//735s033zxr7dVV1kz66a+f++67zxQXF5u8vDwTHR3tOX6jR482Dz/8sGf22e12e86dk9fBv/3tb7Va/7k888wzJjEx0Rhz4lzr2rWryczMLHUenn6ene389ta1/lQnX1dnG++zXZPLui7W1GupJpx6/q1du9Z07drVjB071nO9Ky9TjB492rz22muexznZvylTppj33nvPGHPitT5hwgTz97//3Rw6dMh069bNHD9+3Bhz4vyoyU9SmEk/z7744gv99ttv+t3vfufZVlJSooMHD2rt2rUaOHCgZ/ZsxIgRmjNnTq3XtHz5cg0ZMkQOh0O33367Zs2apT179mjbtm0aMmSIJKlLly6eGZFz+fzzz/W3v/1N+fn5KikpKdUWEBCgAQMGVLrG66+/XnPnztXtt9+uXr16VbiWyihrHPbv3y9J6tWrl0JDQ8+4T35+vr799lvl5OR4th07dkwZGRkaNmyYSkpKNHXqVPXo0aPGZlrPpaCgQNOnT9fWrVvlcDiUlZWln3/+2TMLNHDgQM9Mx9ChQ/Xxxx9r9OjRkqT+/furUaNGZzzmjh07VFJSUurYNW3aVHl5efrpp5905513SpKuuOIKdejQQRs2bFDfvn0lScOGDSv1WLfeeqsCAgIknZjh+O2333TTTTdVub/bt2/XxIkTVVBQoJ49e2rDhg3Ky8tTWlqapBMz61dddVWp5z85K9e2bVv17t1bPj4+atGihYKDg7Vv3z7PWJ2qf//+8vHxUePGjdWuXTv99ttvuuyyy6pcd1Wc69iWN7affvqpVqxYIR+fE19DOnkup6enn3WsyjsfTufj46PFixdr27Zt+u677/TJJ59oyZIlSklJ0cqVK5WSkqLi4mLl5+d7xuybb77RgAEDPI8/dOhQLV68uFbGpaL9ONVVV12ljIwMzZgxQ927d/d8UlOe8sbgySefVLt27XTttddKkpxOp5o0aaKtW7fKz89PN9xwgyTpxhtvlJ+fn3bs2KHAwMAy3ytvueUWXXTRRZKk4cOHl/ndmbVr12rYsGGec/yOO+7QJ598olGjRlWq/zVt6NCh8vX1la+vrwYOHKh169Z53hMHDx4sX98TccTtdusvf/mLPv/8c7ndbh05ckQNGjTwZukaPny4HnjgAU2cOFEffvihrr32WrVs2fKM/U49z852fnvrWl+W6ox3edfF01X2tVRTHn30UQUEBCgoKEjJyclKSUnxtJWVKY4dO6b169fr9ddf9+x36nvlxo0bPW0FBQVq0aKFGjdurEsuucTz6dgtt9ziOa41gZDuBT179lRSUpK3y5B04qKcmpoqf39/z8fZxcXFeu+99856P6fTKbfb7bldWFgoSdqzZ4/mzp2r5cuXq02bNvrxxx89ywIkqWHDhuUubSjvMSVpypQp2rp1q9atW6fx48frvvvu04gRIyrf4XKUNw4nP5os72NIt9sth8Oh5cuXy8/P74z2VatW6ZtvvtHXX3+tBQsW6L333lPz5s2rXW/Hjh21a9cuHTlyxLN04KTnnntOzZs317x58+Tr66sxY8aUGsuzqWyQqcpjngyR0olj7nK5KvV4J/t+9OhRBQcH64orrtDKlSv1xhtvaNOmTTLGaNq0aZ7wc7rTn7+i9VS37oqqzrGtbI3nGqvKng8RERGKiIjQ7373Ow0cOFBvvPGGPvjgAy1btkyhoaFKSUnR22+/XanHrIhzjcvZ+uF0OmWMkVT6PadNmzZKTU3VunXr9Pnnn+v5559XSkpKqTEuy+ljUFVne6+sb049PikpKfrhhx/05ptvKigoSC+//LJn6YG3XHXVVQoLC9Pnn3+ud99917Mk7nS18f5Z28423me7JktnXhdr+rVUXS+88EKpCb1TQ3pZmWLQoEHlPpYxRosXL1abNm3OaHv77bf1448/at26dbrjjjv05z//udRkR3Xw6y7n2U033aQvvvhCv/zyi2fbxo0bJUk33HCDPvzwQ+Xl5ckYo+XLl+vGG2+s1XrWrFmjtm3b6vPPP1d6errS09P1l7/8RR988IEiIiI8J/XGjRtLfXv/kksu0b/+9S9JJ2YFDh48KEnKy8uTn5+fmjdvLrfbXak12Jdeeqk2b94st9utvLw8ffbZZ562X3/9Ve3bt9c999yjmJgYz3PXlPLG4Vz/WAkKClK3bt306quverZlZmbqwIEDysnJ0fHjxz1rQhs3bqzdu3fXSL2XXXaZ+vbtq4SEBOXl5UmSXC6X3nnnHeXm5qply5by9fXVtm3bzvj1gY8++sjzKcfKlSt1/fXXn/P52rZtK19fX3344YeebYcOHVJQUJA6dOjgGaeMjAz9/PPPnu9Y1IbLLrtM/fr101NPPaXc3FzP9vz8fEkn1sIuXbrU8+sdeXl5ysjIqLV6alp1jm15+vTpoyVLlnguoCc/+ampsdq/f7/Wr1/vub1v3z7l5OTI4XAoKChIISEhKioq0rvvvuvZp3v37kpLS9Px48fldrs963NPFxQUpIKCglKfygUGBpY69lUdF6n0e9mpF/F9+/bJ6XTq1ltv1eTJk5WTk6PDhw9Xegwuv/xyZWRkeNpcLpeOHDmitm3bqri4WOvWrZN04n20pKREbdu2Lfc5PvvsM8+xW7FiRZmv3RtuuEHvv/++iouLVVxcrPfff7/WryMV8cEHH6ikpET5+fn68MMPy33fyc3NVdOmTRUUFKTc3Fylpqae50rLdueddyo5OVk7d+5Uv379zrn/2c5vb1zry3O28T7bNbksNfVaOh/KyhSBgYHq2rVrqV9KOvW98tVXX/VMfOTk5Gj37t3Ky8tTTk6OunfvrkcffVQRERGl8l11MZN+Htx3332lvrTz9NNPa+rUqSooKFBxcbGuvfZade7cWb1799bWrVs1cuRISVKnTp00duzYWq3t3Xff1eDBg0tt69q1q9xut+Lj4zV//ny99tprioiI0DXXXOPZZ/z48YqPj9cbb7yh66+/Xq1atZJ04osi/fv318CBA9W0aVP17t27whfM2267TatXr9aAAQPUqlUrXX311Z62Z599Vrt27ZLT6VRwcLBmz55dA73/j7ONw7fffqtOnTqVe98FCxZo7ty5nvsHBgZq9uzZKigo0NNPP62SkhK5XC716tWrRsPrvHnztGjRIt15553y8/OT2+1W79699eCDD2rKlClavny52rZtq+uuu67U/a655hqNGTPG88ZSkU8kfH19tXjxYs2cOVOLFy+Ww+HQmDFjNHToUC1YsEAJCQlaunSpfH19lZSUVKGPQKtj7ty5Wrx4sYYPHy5fX18FBwcrLCxMDz30kCIiIvTiiy9q+PDhcjgccjgcGjduXJlLWGxV1WNbnsmTJ2vOnDmKjo6W0+lU9+7d9dRTT+mhhx6qkbEqKSlRcnKy9uzZowYNGsjtduuxxx7TnXfeqV9++UVRUVFq2rSpIiMjPRfxfv36af369YqJiVGTJk3UpUsXHTly5IzHDgkJ0eDBgzV48GA1adJEy5YtU2xsrObNm6clS5YoLi5OY8eO1aRJkyo9LifHJiEhQY0bN1b//v0927du3apnn31W0olPzB566CG1aNGi0mPQqVMnJScna968ecrPz/d8ie7GG2/UCy+8UOqLowsXLjzrFyQjIyM1YcIE7d+/X1dccYXi4+PP2Cc2Nla//fabZ5nZzTffXKOfOpbn9OvcyS/JnnT55Zdr5MiRni+Olrf8b+jQoVqzZo369++vZs2aqVu3bhX+JLA2RUdHKzExUSNGjKjQl1jPdn5741pfnrON99muyWWpqdfS+VBepliwYIFmzJih6Oho+fj4KDo6Wg899JCmTJmi+fPne5bE+vn5acqUKfLz89Mf//hHFRQUyBijjh076vbbb6+xOh3m5NQKcA41/SsWOP/i4+PVqVMnzxp0wJvy8vIUFBQkt9utqVOnKiwsTBMmTPB2WVY6/Zc2YD/Ob1QXM+kAAK+Ii4vTnj17VFBQoKuvvloPPvigt0sCagznN6qLmXQAAADAMnxxFAAAALAMIR0AAACwDCEdAAAAsAwhHQBQKS+//LKmTp3q7TIAoF7ji6MAAACAZZhJBwAAACxDSAcAlOvVV19Vz5491bVrV0VFRWnt2rVKTk7WE0884dnn/fffV58+fdSjRw8tWrRIffv21ddffy3pxH/CM378eE2aNEldu3bVoEGDPP/rKACgfIR0AECZfv31V7355ptavny51q9fryVLlqh169al9tm+fbtmzJih+fPn64svvlBeXp72799fap/09HQNGjRI33//vfr27atnnnnmfHYDAOokQjoAoExOp1NFRUXKyMhQcXGxLr74Yl1yySWl9vnoo4/Up08fRUZGyt/fX48++qgcDkepfbp166bevXvL6XRqyJAh+vnnn89nNwCgTiKkAwDKdOmll2rKlClKTk7WjTfeqAkTJpwxS56VlaWWLVt6bjds2FAhISGl9rnooos8f2/QoIEKCwtVUlJSu8UDQB1HSAcAlGvw4MF666239Omnn8rhcGjBggWl2sPCwkoF94KCAh0+fPh8lwkA9Q4hHQBQpl9//VVr165VUVGR/P39FRAQIB+f0peNqKgopaen68cff1RRUZGSk5PFL/sCQPUR0gEAZSoqKtKzzz6rHj166Oabb1ZOTo4ef/zxUvtceeWVevrpp/X444+rZ8+eatSokUJDQ+Xv7++lqgGgfuA/MwIA1Jhjx47puuuuU1pamtq0aePtcgCgzmImHQBQLenp6Tp+/Ljy8/OVmJioiIgIXXzxxd4uCwDqNEI6AKBa1qxZo549e6pnz57atWuXnnvuuTN+hhEAUDksdwEAAAAsw0w6AAAAYBlCOgAAAGAZQjoAAABgGUI6AAAAYBlCOgAAAGAZQjoAAABgmf8H/FY5NPlrFEsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIimQOX_YCzQ"
      },
      "source": [
        "## **2. Perform data pre-processing on the data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q51sA7yeYOrw"
      },
      "source": [
        "### Data cleansing by removing unwanted characters, spaces, stop words etc. Convert text to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRlVaORfYN9P"
      },
      "source": [
        "# Remove unwanted chars other than alphanumeric\n",
        "\n",
        "pattern = \"[^\\w]\"\n",
        "df_new.text = df_new.text.apply(lambda s : re.sub(pattern,' ',s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "J_bVNvGuXYNS",
        "outputId": "f1e7f38b-a577-46fe-93f1-6fe0b1cd1aee"
      },
      "source": [
        "df_new.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>topic</th>\n",
              "      <th>sign</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>93407</th>\n",
              "      <td>324114</td>\n",
              "      <td>female</td>\n",
              "      <td>46</td>\n",
              "      <td>Consulting</td>\n",
              "      <td>Capricorn</td>\n",
              "      <td>19,May,2002</td>\n",
              "      <td>urlLink       I don t know about...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52173</th>\n",
              "      <td>3718134</td>\n",
              "      <td>male</td>\n",
              "      <td>25</td>\n",
              "      <td>Arts</td>\n",
              "      <td>Scorpio</td>\n",
              "      <td>08,June,2003</td>\n",
              "      <td>Why is there such resistance out th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45621</th>\n",
              "      <td>2002478</td>\n",
              "      <td>male</td>\n",
              "      <td>25</td>\n",
              "      <td>Science</td>\n",
              "      <td>Sagittarius</td>\n",
              "      <td>19,March,2004</td>\n",
              "      <td>Welcome readers  old and new  Hello Ada...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10790</th>\n",
              "      <td>4004267</td>\n",
              "      <td>male</td>\n",
              "      <td>33</td>\n",
              "      <td>LawEnforcement-Security</td>\n",
              "      <td>Taurus</td>\n",
              "      <td>10,August,2004</td>\n",
              "      <td>When I am Old     I shall wear Turquois...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53644</th>\n",
              "      <td>899153</td>\n",
              "      <td>female</td>\n",
              "      <td>27</td>\n",
              "      <td>Religion</td>\n",
              "      <td>Gemini</td>\n",
              "      <td>16,December,2002</td>\n",
              "      <td>lay me down in sheets of linen  you h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  ...                                               text\n",
              "93407   324114  ...                urlLink       I don t know about...\n",
              "52173  3718134  ...             Why is there such resistance out th...\n",
              "45621  2002478  ...         Welcome readers  old and new  Hello Ada...\n",
              "10790  4004267  ...         When I am Old     I shall wear Turquois...\n",
              "53644   899153  ...           lay me down in sheets of linen  you h...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IWM9THSZRh0"
      },
      "source": [
        "# Coverting text to lowercase\n",
        "\n",
        "df_new.text = df_new.text.apply(lambda s : s.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "5Py-LhZsZpSC",
        "outputId": "bd9f5114-7a73-4b66-8971-aee35f399008"
      },
      "source": [
        "df_new.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>topic</th>\n",
              "      <th>sign</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3618</th>\n",
              "      <td>589736</td>\n",
              "      <td>male</td>\n",
              "      <td>35</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Aries</td>\n",
              "      <td>05,August,2004</td>\n",
              "      <td>from ebert       films like  the ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39155</th>\n",
              "      <td>4002052</td>\n",
              "      <td>female</td>\n",
              "      <td>23</td>\n",
              "      <td>Education</td>\n",
              "      <td>Capricorn</td>\n",
              "      <td>08,August,2004</td>\n",
              "      <td>urllink    alyson wong     p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6575</th>\n",
              "      <td>883178</td>\n",
              "      <td>male</td>\n",
              "      <td>36</td>\n",
              "      <td>Fashion</td>\n",
              "      <td>Aries</td>\n",
              "      <td>18,November,2002</td>\n",
              "      <td>that s a funny question  because of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1685</th>\n",
              "      <td>589736</td>\n",
              "      <td>male</td>\n",
              "      <td>35</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Aries</td>\n",
              "      <td>05,August,2004</td>\n",
              "      <td>i know the feeling you are going th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15039</th>\n",
              "      <td>4036173</td>\n",
              "      <td>female</td>\n",
              "      <td>24</td>\n",
              "      <td>Arts</td>\n",
              "      <td>Sagittarius</td>\n",
              "      <td>25,July,2004</td>\n",
              "      <td>this is my very first blog post   ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14915</th>\n",
              "      <td>727002</td>\n",
              "      <td>male</td>\n",
              "      <td>23</td>\n",
              "      <td>Internet</td>\n",
              "      <td>Leo</td>\n",
              "      <td>12,December,2003</td>\n",
              "      <td>so i m taking next friday off  gi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72629</th>\n",
              "      <td>2349682</td>\n",
              "      <td>female</td>\n",
              "      <td>24</td>\n",
              "      <td>Education</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>12,May,2004</td>\n",
              "      <td>today i had lunch with my gra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50910</th>\n",
              "      <td>3986440</td>\n",
              "      <td>male</td>\n",
              "      <td>23</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>Leo</td>\n",
              "      <td>03,August,2004</td>\n",
              "      <td>poker has been good to me so far  with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13559</th>\n",
              "      <td>1976124</td>\n",
              "      <td>male</td>\n",
              "      <td>25</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Libra</td>\n",
              "      <td>24,April,2004</td>\n",
              "      <td>work  work  work   ugh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3813</th>\n",
              "      <td>3543234</td>\n",
              "      <td>male</td>\n",
              "      <td>14</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Scorpio</td>\n",
              "      <td>13,June,2004</td>\n",
              "      <td>do not try to bend the spoon  becau...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  ...                                               text\n",
              "3618    589736  ...             from ebert       films like  the ch...\n",
              "39155  4002052  ...                    urllink    alyson wong     p...\n",
              "6575    883178  ...             that s a funny question  because of...\n",
              "1685    589736  ...             i know the feeling you are going th...\n",
              "15039  4036173  ...              this is my very first blog post   ...\n",
              "14915   727002  ...               so i m taking next friday off  gi...\n",
              "72629  2349682  ...                   today i had lunch with my gra...\n",
              "50910  3986440  ...          poker has been good to me so far  with...\n",
              "13559  1976124  ...                   work  work  work   ugh          \n",
              "3813   3543234  ...             do not try to bend the spoon  becau...\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSgydr0RZr6Z"
      },
      "source": [
        "# Removing unwanted spaces\n",
        "\n",
        "df_new.text = df_new.text.apply(lambda s : s.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "OBgyynudaHdR",
        "outputId": "a686786b-041c-4e25-e99e-28bd1fd765bf"
      },
      "source": [
        "df_new.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>topic</th>\n",
              "      <th>sign</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>59157</th>\n",
              "      <td>2163386</td>\n",
              "      <td>male</td>\n",
              "      <td>26</td>\n",
              "      <td>Government</td>\n",
              "      <td>Taurus</td>\n",
              "      <td>18,April,2004</td>\n",
              "      <td>tomorrow i m going to make an appointment with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36792</th>\n",
              "      <td>152151</td>\n",
              "      <td>female</td>\n",
              "      <td>23</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>Libra</td>\n",
              "      <td>19,March,2001</td>\n",
              "      <td>i was talking to some friends yesterday and we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56471</th>\n",
              "      <td>2217862</td>\n",
              "      <td>female</td>\n",
              "      <td>42</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Scorpio</td>\n",
              "      <td>16,June,2004</td>\n",
              "      <td>urllink    this is one of my favourite places ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38946</th>\n",
              "      <td>3955165</td>\n",
              "      <td>female</td>\n",
              "      <td>23</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Sagittarius</td>\n",
              "      <td>16,August,2004</td>\n",
              "      <td>whitey houston and vertical struts   side trac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96083</th>\n",
              "      <td>4000026</td>\n",
              "      <td>male</td>\n",
              "      <td>17</td>\n",
              "      <td>Education</td>\n",
              "      <td>Gemini</td>\n",
              "      <td>27,July,2004</td>\n",
              "      <td>it was just awesome today  5 maths period free...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95666</th>\n",
              "      <td>751202</td>\n",
              "      <td>female</td>\n",
              "      <td>33</td>\n",
              "      <td>Internet</td>\n",
              "      <td>Gemini</td>\n",
              "      <td>24,July,2003</td>\n",
              "      <td>ah lazy dayz      i ve done nowt today   i ve ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42769</th>\n",
              "      <td>3326689</td>\n",
              "      <td>male</td>\n",
              "      <td>14</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Cancer</td>\n",
              "      <td>12,May,2004</td>\n",
              "      <td>june 2  2004  at jagex we take a great pride i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24790</th>\n",
              "      <td>546850</td>\n",
              "      <td>male</td>\n",
              "      <td>24</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Aries</td>\n",
              "      <td>27,February,2003</td>\n",
              "      <td>the tides of war  the ides of march   i recall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81278</th>\n",
              "      <td>3899528</td>\n",
              "      <td>male</td>\n",
              "      <td>16</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Scorpio</td>\n",
              "      <td>31,July,2004</td>\n",
              "      <td>i seal my tots in de clouds   it floats across...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3232</th>\n",
              "      <td>589736</td>\n",
              "      <td>male</td>\n",
              "      <td>35</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Aries</td>\n",
              "      <td>05,August,2004</td>\n",
              "      <td>pentagon holding terror drill    top pentagon ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  ...                                               text\n",
              "59157  2163386  ...  tomorrow i m going to make an appointment with...\n",
              "36792   152151  ...  i was talking to some friends yesterday and we...\n",
              "56471  2217862  ...  urllink    this is one of my favourite places ...\n",
              "38946  3955165  ...  whitey houston and vertical struts   side trac...\n",
              "96083  4000026  ...  it was just awesome today  5 maths period free...\n",
              "95666   751202  ...  ah lazy dayz      i ve done nowt today   i ve ...\n",
              "42769  3326689  ...  june 2  2004  at jagex we take a great pride i...\n",
              "24790   546850  ...  the tides of war  the ides of march   i recall...\n",
              "81278  3899528  ...  i seal my tots in de clouds   it floats across...\n",
              "3232    589736  ...  pentagon holding terror drill    top pentagon ...\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFs_y44aaIb5"
      },
      "source": [
        "# Removing stopwords\n",
        "\n",
        "stopwords = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex5uZ4IEaW1f"
      },
      "source": [
        "df_new.text  = df_new.text.apply(lambda t : ' '. join([words for words in t.split() if words not in stopwords]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "n_YxVr_yb2Xc",
        "outputId": "9e4ccf16-4f38-4578-8380-4a553699bd91"
      },
      "source": [
        "df_new.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>topic</th>\n",
              "      <th>sign</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64515</th>\n",
              "      <td>1852920</td>\n",
              "      <td>female</td>\n",
              "      <td>25</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Sagittarius</td>\n",
              "      <td>18,May,2004</td>\n",
              "      <td>computer wants repress feelings poured heart y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39350</th>\n",
              "      <td>3672856</td>\n",
              "      <td>male</td>\n",
              "      <td>16</td>\n",
              "      <td>Student</td>\n",
              "      <td>Scorpio</td>\n",
              "      <td>26,July,2004</td>\n",
              "      <td>yup braces im free man look better though dont...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77159</th>\n",
              "      <td>2529236</td>\n",
              "      <td>male</td>\n",
              "      <td>24</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Cancer</td>\n",
              "      <td>08,July,2004</td>\n",
              "      <td>yesterday tom ridge reminded us osama bin lade...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81913</th>\n",
              "      <td>1903669</td>\n",
              "      <td>female</td>\n",
              "      <td>14</td>\n",
              "      <td>Non-Profit</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>06,November,2003</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70915</th>\n",
              "      <td>3358192</td>\n",
              "      <td>female</td>\n",
              "      <td>16</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Aries</td>\n",
              "      <td>16,May,2004</td>\n",
              "      <td>mood bored ah yes found blogger thanks lovely ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5399</th>\n",
              "      <td>1103575</td>\n",
              "      <td>female</td>\n",
              "      <td>17</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Scorpio</td>\n",
              "      <td>14,July,2004</td>\n",
              "      <td>sigh bored already oh well st robert kids make...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88525</th>\n",
              "      <td>320317</td>\n",
              "      <td>male</td>\n",
              "      <td>36</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Pisces</td>\n",
              "      <td>15,October,2002</td>\n",
              "      <td>cable operators like brag revolutionized tv ke...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99826</th>\n",
              "      <td>3446810</td>\n",
              "      <td>female</td>\n",
              "      <td>17</td>\n",
              "      <td>Communications-Media</td>\n",
              "      <td>Scorpio</td>\n",
              "      <td>28,June,2004</td>\n",
              "      <td>know nobody give kind guarantee think want som...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70868</th>\n",
              "      <td>3640328</td>\n",
              "      <td>female</td>\n",
              "      <td>45</td>\n",
              "      <td>Arts</td>\n",
              "      <td>Scorpio</td>\n",
              "      <td>12,July,2004</td>\n",
              "      <td>rooting mail found nifty catalog really expens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93528</th>\n",
              "      <td>324114</td>\n",
              "      <td>female</td>\n",
              "      <td>46</td>\n",
              "      <td>Consulting</td>\n",
              "      <td>Capricorn</td>\n",
              "      <td>01,November,2002</td>\n",
              "      <td>weekend gonna give urllink haloscan try commen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  ...                                               text\n",
              "64515  1852920  ...  computer wants repress feelings poured heart y...\n",
              "39350  3672856  ...  yup braces im free man look better though dont...\n",
              "77159  2529236  ...  yesterday tom ridge reminded us osama bin lade...\n",
              "81913  1903669  ...                                                   \n",
              "70915  3358192  ...  mood bored ah yes found blogger thanks lovely ...\n",
              "5399   1103575  ...  sigh bored already oh well st robert kids make...\n",
              "88525   320317  ...  cable operators like brag revolutionized tv ke...\n",
              "99826  3446810  ...  know nobody give kind guarantee think want som...\n",
              "70868  3640328  ...  rooting mail found nifty catalog really expens...\n",
              "93528   324114  ...  weekend gonna give urllink haloscan try commen...\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tlNHWevb6iq"
      },
      "source": [
        "# Dropping id and date columns in the dataset\n",
        "\n",
        "df_new.drop(labels = ['id', 'date'], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "8_el8BLacSHb",
        "outputId": "daf4f471-86d0-4be1-bec8-b0e87593266b"
      },
      "source": [
        "df_new.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>topic</th>\n",
              "      <th>sign</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50089</th>\n",
              "      <td>male</td>\n",
              "      <td>27</td>\n",
              "      <td>Government</td>\n",
              "      <td>Sagittarius</td>\n",
              "      <td>urllink plane boeing 777 flew go england nice ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11533</th>\n",
              "      <td>female</td>\n",
              "      <td>27</td>\n",
              "      <td>Publishing</td>\n",
              "      <td>Scorpio</td>\n",
              "      <td>hello dearest beautiful gal frens nbsp blog la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82133</th>\n",
              "      <td>male</td>\n",
              "      <td>26</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Scorpio</td>\n",
              "      <td>unsurprisingly berg execution made much impact...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11287</th>\n",
              "      <td>male</td>\n",
              "      <td>23</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>urllink super prefix means upon superior size ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22279</th>\n",
              "      <td>female</td>\n",
              "      <td>27</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Gemini</td>\n",
              "      <td>men desire virgin whore edward dahlberg died y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9206</th>\n",
              "      <td>female</td>\n",
              "      <td>24</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Sagittarius</td>\n",
              "      <td>urllink las meninas velasquez el prado madrid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64417</th>\n",
              "      <td>female</td>\n",
              "      <td>23</td>\n",
              "      <td>Chemicals</td>\n",
              "      <td>Capricorn</td>\n",
              "      <td>dinner one arab street food stores tks treatin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29085</th>\n",
              "      <td>female</td>\n",
              "      <td>33</td>\n",
              "      <td>Internet</td>\n",
              "      <td>Taurus</td>\n",
              "      <td>kind like answering silly quiz questions know ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47721</th>\n",
              "      <td>female</td>\n",
              "      <td>17</td>\n",
              "      <td>Student</td>\n",
              "      <td>Capricorn</td>\n",
              "      <td>think jo still comes well fuck feels like dat ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20766</th>\n",
              "      <td>male</td>\n",
              "      <td>16</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Leo</td>\n",
              "      <td>man bored high schools sucks got work actually...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       gender  ...                                               text\n",
              "50089    male  ...  urllink plane boeing 777 flew go england nice ...\n",
              "11533  female  ...  hello dearest beautiful gal frens nbsp blog la...\n",
              "82133    male  ...  unsurprisingly berg execution made much impact...\n",
              "11287    male  ...  urllink super prefix means upon superior size ...\n",
              "22279  female  ...  men desire virgin whore edward dahlberg died y...\n",
              "9206   female  ...      urllink las meninas velasquez el prado madrid\n",
              "64417  female  ...  dinner one arab street food stores tks treatin...\n",
              "29085  female  ...  kind like answering silly quiz questions know ...\n",
              "47721  female  ...  think jo still comes well fuck feels like dat ...\n",
              "20766    male  ...  man bored high schools sucks got work actually...\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNb8h735chns"
      },
      "source": [
        "### Target/label merger and transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwFd_qu0cUh7"
      },
      "source": [
        "df_new['labels'] = df_new.apply(lambda col : [col['gender'], col['age'], col['topic'], col['sign']], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XCIv0JqdMJy"
      },
      "source": [
        "# Drop gender,age,topic & sign as they are already merged to labels column\n",
        "\n",
        "df_new.drop(columns = ['gender','age','topic','sign'], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "fRTvcwLZimam",
        "outputId": "07d28312-069d-4b2d-952d-701e0f56f15e"
      },
      "source": [
        "df_new.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9134</th>\n",
              "      <td>came one house dance light feet kiss fingers l...</td>\n",
              "      <td>[female, 24, indUnk, Sagittarius]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95980</th>\n",
              "      <td>went last night sister drinks search man amazi...</td>\n",
              "      <td>[female, 25, Student, Taurus]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88660</th>\n",
              "      <td>idc reports pc shipments worldwide grew 1 5 20...</td>\n",
              "      <td>[male, 36, Technology, Pisces]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20112</th>\n",
              "      <td>okay month officially lost twice lost seoul am...</td>\n",
              "      <td>[female, 27, Education, Cancer]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35994</th>\n",
              "      <td>okay woke really late morning usually means ti...</td>\n",
              "      <td>[female, 16, Student, Sagittarius]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41996</th>\n",
              "      <td>happy 6th birthday andrew show great got odeon...</td>\n",
              "      <td>[female, 24, indUnk, Libra]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22418</th>\n",
              "      <td>well would seem everyone go ben lately well we...</td>\n",
              "      <td>[male, 17, Student, Cancer]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99894</th>\n",
              "      <td>jeevan ke har mod par mil jaate hain humsafar ...</td>\n",
              "      <td>[female, 27, Advertising, Aquarius]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29525</th>\n",
              "      <td>merciful lord blinded horror honestly think tr...</td>\n",
              "      <td>[female, 27, Government, Leo]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37615</th>\n",
              "      <td>safely contained illusive sactuary fragile wal...</td>\n",
              "      <td>[male, 36, Arts, Virgo]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text                               labels\n",
              "9134   came one house dance light feet kiss fingers l...    [female, 24, indUnk, Sagittarius]\n",
              "95980  went last night sister drinks search man amazi...        [female, 25, Student, Taurus]\n",
              "88660  idc reports pc shipments worldwide grew 1 5 20...       [male, 36, Technology, Pisces]\n",
              "20112  okay month officially lost twice lost seoul am...      [female, 27, Education, Cancer]\n",
              "35994  okay woke really late morning usually means ti...   [female, 16, Student, Sagittarius]\n",
              "41996  happy 6th birthday andrew show great got odeon...          [female, 24, indUnk, Libra]\n",
              "22418  well would seem everyone go ben lately well we...          [male, 17, Student, Cancer]\n",
              "99894  jeevan ke har mod par mil jaate hain humsafar ...  [female, 27, Advertising, Aquarius]\n",
              "29525  merciful lord blinded horror honestly think tr...        [female, 27, Government, Leo]\n",
              "37615  safely contained illusive sactuary fragile wal...              [male, 36, Arts, Virgo]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAvjMb43jOD3"
      },
      "source": [
        "## Train and test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL5FynwSipNN"
      },
      "source": [
        "x = df_new.text\n",
        "y = df_new.labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXgY4gF4jd8Q"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 1)        # Splitting data into training and testing set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQeU6kQajtdb",
        "outputId": "7b9b6424-6205-4f15-b7b8-2f599b4eb713"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80000,)\n",
            "(80000,)\n",
            "(20000,)\n",
            "(20000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLDpRMhpkJjw",
        "outputId": "60c32b5d-110d-4798-bd35-e4041845221b"
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78689    talking gal online chatted asked see pic showe...\n",
              "76423    hey everybody started another painting yesterd...\n",
              "86945    possibly need burn 2 ladders quote day power m...\n",
              "57427    heart red urllink color heart brought urllink ...\n",
              "34616    anything today woke 2pm hehehe made one ramen ...\n",
              "                               ...                        \n",
              "50057    method post urllink wild animal name username ...\n",
              "98047    days rose bloom really like macro function nev...\n",
              "5192     today dies cinerum lovely latin tells mean lit...\n",
              "77708    awesome create blog keep posting choose templa...\n",
              "98539    attention hamptons shoppers hottest talked wri...\n",
              "Name: text, Length: 80000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUnbodcFkMHl",
        "outputId": "e2b3c839-c07f-40b8-da4b-3b3dcd86e748"
      },
      "source": [
        "x_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43660    urllink information literacy wikipedia new art...\n",
              "87278    sorry reading town day get practice make voice...\n",
              "14317    happy birthday dad well huge news everyone goi...\n",
              "81932    bothered wake 6 00 morning watch world idol re...\n",
              "95321    artist beatles album let song let lennon mccar...\n",
              "                               ...                        \n",
              "73441    welcome course contrary title post means begin...\n",
              "1341     weird feelings everything gonna talk 1 cuz one...\n",
              "71987    birthday means drinking tonight dude pretty di...\n",
              "26910    read lyle blog could say chance man desperate ...\n",
              "24890    sin one ring hit today tolkien description one...\n",
              "Name: text, Length: 20000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA29JEJCj_en"
      },
      "source": [
        "## Vectorisation, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5XFQOXZjywK"
      },
      "source": [
        "convec = CountVectorizer(ngram_range=(1,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zosyvk7JkXs2",
        "outputId": "536f240c-29da-4787-ecd9-62902cd35017"
      },
      "source": [
        "# Feed data into CountVectorizer\n",
        "convec.fit(x_train)\n",
        "\n",
        "# Check vocabulary size \n",
        "len(convec.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4262296"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb_HbxZRkzco",
        "outputId": "d7e878c9-21d7-4651-d503-f22bdd744a42"
      },
      "source": [
        "convec.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00',\n",
              " '00 00',\n",
              " '00 000',\n",
              " '00 00a',\n",
              " '00 00am',\n",
              " '00 01',\n",
              " '00 03',\n",
              " '00 04',\n",
              " '00 05',\n",
              " '00 07',\n",
              " '00 08',\n",
              " '00 0800',\n",
              " '00 09',\n",
              " '00 10',\n",
              " '00 11',\n",
              " '00 12',\n",
              " '00 120',\n",
              " '00 15',\n",
              " '00 17',\n",
              " '00 18',\n",
              " '00 20',\n",
              " '00 2004',\n",
              " '00 21',\n",
              " '00 23',\n",
              " '00 27',\n",
              " '00 28',\n",
              " '00 29',\n",
              " '00 2nd',\n",
              " '00 30',\n",
              " '00 300',\n",
              " '00 30am',\n",
              " '00 30ish',\n",
              " '00 30pm',\n",
              " '00 31st',\n",
              " '00 32',\n",
              " '00 34',\n",
              " '00 35',\n",
              " '00 36',\n",
              " '00 39',\n",
              " '00 40',\n",
              " '00 400',\n",
              " '00 41',\n",
              " '00 42',\n",
              " '00 44',\n",
              " '00 45',\n",
              " '00 47',\n",
              " '00 50',\n",
              " '00 500',\n",
              " '00 55',\n",
              " '00 56',\n",
              " '00 57',\n",
              " '00 59',\n",
              " '00 6lbs',\n",
              " '00 780',\n",
              " '00 81',\n",
              " '00 90',\n",
              " '00 96',\n",
              " '00 able',\n",
              " '00 according',\n",
              " '00 actually',\n",
              " '00 adelphi',\n",
              " '00 admission',\n",
              " '00 admit',\n",
              " '00 adwords',\n",
              " '00 afi',\n",
              " '00 afternoon',\n",
              " '00 ahead',\n",
              " '00 ahh',\n",
              " '00 airfare',\n",
              " '00 alarm',\n",
              " '00 alll',\n",
              " '00 allrite',\n",
              " '00 almost',\n",
              " '00 already',\n",
              " '00 alright',\n",
              " '00 also',\n",
              " '00 although',\n",
              " '00 american',\n",
              " '00 andwe',\n",
              " '00 another',\n",
              " '00 anymore',\n",
              " '00 anyone',\n",
              " '00 anytime',\n",
              " '00 anyway',\n",
              " '00 apple',\n",
              " '00 appointment',\n",
              " '00 approaches',\n",
              " '00 ara',\n",
              " '00 around',\n",
              " '00 arrive',\n",
              " '00 arrived',\n",
              " '00 arrives',\n",
              " '00 ashamed',\n",
              " '00 asia',\n",
              " '00 asked',\n",
              " '00 assure',\n",
              " '00 ataris',\n",
              " '00 ate',\n",
              " '00 august',\n",
              " '00 available',\n",
              " '00 awake',\n",
              " '00 awarded',\n",
              " '00 awesome',\n",
              " '00 awkward',\n",
              " '00 babysitting',\n",
              " '00 babystyle',\n",
              " '00 back',\n",
              " '00 background',\n",
              " '00 bad',\n",
              " '00 balance',\n",
              " '00 band',\n",
              " '00 bank',\n",
              " '00 bar',\n",
              " '00 barely',\n",
              " '00 baseball',\n",
              " '00 based',\n",
              " '00 basically',\n",
              " '00 bdv',\n",
              " '00 bean',\n",
              " '00 becase',\n",
              " '00 become',\n",
              " '00 bed',\n",
              " '00 bedtime',\n",
              " '00 beer',\n",
              " '00 begged',\n",
              " '00 begin',\n",
              " '00 beging',\n",
              " '00 beginning',\n",
              " '00 bein',\n",
              " '00 believe',\n",
              " '00 ben',\n",
              " '00 best',\n",
              " '00 beth',\n",
              " '00 better',\n",
              " '00 bible',\n",
              " '00 big',\n",
              " '00 bills',\n",
              " '00 bio',\n",
              " '00 black',\n",
              " '00 blah',\n",
              " '00 bless',\n",
              " '00 blogging',\n",
              " '00 bole',\n",
              " '00 bookings',\n",
              " '00 bored',\n",
              " '00 bottle',\n",
              " '00 bottles',\n",
              " '00 bowling',\n",
              " '00 boys',\n",
              " '00 brainless',\n",
              " '00 brains',\n",
              " '00 brandi',\n",
              " '00 brandon',\n",
              " '00 breakfast',\n",
              " '00 bring',\n",
              " '00 brings',\n",
              " '00 brooke',\n",
              " '00 brothers',\n",
              " '00 bullshit',\n",
              " '00 bus',\n",
              " '00 bux',\n",
              " '00 buy',\n",
              " '00 bye',\n",
              " '00 call',\n",
              " '00 came',\n",
              " '00 canadian',\n",
              " '00 candy',\n",
              " '00 cannot',\n",
              " '00 cant',\n",
              " '00 capoeira',\n",
              " '00 car',\n",
              " '00 cars',\n",
              " '00 carwash',\n",
              " '00 cd',\n",
              " '00 cedar',\n",
              " '00 central',\n",
              " '00 chance',\n",
              " '00 changed',\n",
              " '00 charge',\n",
              " '00 chatted',\n",
              " '00 cheap',\n",
              " '00 cheaper',\n",
              " '00 check',\n",
              " '00 cheers',\n",
              " '00 cheeseburger',\n",
              " '00 cherry',\n",
              " '00 cheyenne',\n",
              " '00 chicks',\n",
              " '00 chillin',\n",
              " '00 chimes',\n",
              " '00 chose',\n",
              " '00 chuck',\n",
              " '00 church',\n",
              " '00 cigar',\n",
              " '00 cigars',\n",
              " '00 class',\n",
              " '00 cleaning',\n",
              " '00 cleans',\n",
              " '00 clocked',\n",
              " '00 closed',\n",
              " '00 closest',\n",
              " '00 closing',\n",
              " '00 come',\n",
              " '00 committee',\n",
              " '00 comp',\n",
              " '00 company',\n",
              " '00 completely',\n",
              " '00 computer',\n",
              " '00 connected',\n",
              " '00 consider',\n",
              " '00 cool',\n",
              " '00 copy',\n",
              " '00 cost',\n",
              " '00 could',\n",
              " '00 couple',\n",
              " '00 court',\n",
              " '00 cover',\n",
              " '00 credit',\n",
              " '00 cross',\n",
              " '00 crown',\n",
              " '00 cup',\n",
              " '00 current',\n",
              " '00 currently',\n",
              " '00 cuz',\n",
              " '00 dadduf',\n",
              " '00 damn',\n",
              " '00 darn',\n",
              " '00 david',\n",
              " '00 day',\n",
              " '00 daylight',\n",
              " '00 days',\n",
              " '00 deadline',\n",
              " '00 deal',\n",
              " '00 dear',\n",
              " '00 debate',\n",
              " '00 decided',\n",
              " '00 deficit',\n",
              " '00 depending',\n",
              " '00 dern',\n",
              " '00 dessert',\n",
              " '00 destination',\n",
              " '00 develop',\n",
              " '00 diapers',\n",
              " '00 dinner',\n",
              " '00 dodge',\n",
              " '00 dollars',\n",
              " '00 done',\n",
              " '00 dont',\n",
              " '00 dot',\n",
              " '00 downpayment',\n",
              " '00 dozen',\n",
              " '00 drawing',\n",
              " '00 drinks',\n",
              " '00 drive',\n",
              " '00 driver',\n",
              " '00 driving',\n",
              " '00 dropkick',\n",
              " '00 drove',\n",
              " '00 drunk',\n",
              " '00 dude',\n",
              " '00 due',\n",
              " '00 duke',\n",
              " '00 dunno',\n",
              " '00 dvd',\n",
              " '00 earliest',\n",
              " '00 early',\n",
              " '00 eastern',\n",
              " '00 eat',\n",
              " '00 ebay',\n",
              " '00 editor',\n",
              " '00 edt',\n",
              " '00 ellie',\n",
              " '00 empty',\n",
              " '00 end',\n",
              " '00 ended',\n",
              " '00 ends',\n",
              " '00 english',\n",
              " '00 enjoyed',\n",
              " '00 enjoying',\n",
              " '00 enron',\n",
              " '00 enthu',\n",
              " '00 envelopes',\n",
              " '00 especially',\n",
              " '00 est',\n",
              " '00 etc',\n",
              " '00 even',\n",
              " '00 evening',\n",
              " '00 eventually',\n",
              " '00 every',\n",
              " '00 everything',\n",
              " '00 exactly',\n",
              " '00 excellent',\n",
              " '00 exception',\n",
              " '00 excited',\n",
              " '00 exciting',\n",
              " '00 exhausting',\n",
              " '00 expense',\n",
              " '00 expensive',\n",
              " '00 fact',\n",
              " '00 fairly',\n",
              " '00 fall',\n",
              " '00 farragut',\n",
              " '00 fashionably',\n",
              " '00 fedora',\n",
              " '00 feel',\n",
              " '00 feeling',\n",
              " '00 fell',\n",
              " '00 felt',\n",
              " '00 figured',\n",
              " '00 filled',\n",
              " '00 final',\n",
              " '00 finally',\n",
              " '00 fine',\n",
              " '00 finish',\n",
              " '00 finished',\n",
              " '00 first',\n",
              " '00 five',\n",
              " '00 fix',\n",
              " '00 fixed',\n",
              " '00 flasher',\n",
              " '00 flat',\n",
              " '00 following',\n",
              " '00 forget',\n",
              " '00 fortunate',\n",
              " '00 found',\n",
              " '00 freaking',\n",
              " '00 free',\n",
              " '00 friday',\n",
              " '00 friend',\n",
              " '00 frost',\n",
              " '00 fucking',\n",
              " '00 fun',\n",
              " '00 fund',\n",
              " '00 gallon',\n",
              " '00 game',\n",
              " '00 games',\n",
              " '00 gbp',\n",
              " '00 geez',\n",
              " '00 general',\n",
              " '00 geometry',\n",
              " '00 get',\n",
              " '00 gets',\n",
              " '00 getting',\n",
              " '00 ghz',\n",
              " '00 gift',\n",
              " '00 ginormous',\n",
              " '00 gives',\n",
              " '00 go',\n",
              " '00 god',\n",
              " '00 goes',\n",
              " '00 going',\n",
              " '00 gone',\n",
              " '00 goner',\n",
              " '00 gonna',\n",
              " '00 good',\n",
              " '00 goodness',\n",
              " '00 got',\n",
              " '00 grabbed',\n",
              " '00 grandma',\n",
              " '00 great',\n",
              " '00 groaned',\n",
              " '00 gucci',\n",
              " '00 guess',\n",
              " '00 gulf',\n",
              " '00 ha',\n",
              " '00 hacking',\n",
              " '00 hair',\n",
              " '00 half',\n",
              " '00 hand',\n",
              " '00 happened',\n",
              " '00 happening',\n",
              " '00 happens',\n",
              " '00 happy',\n",
              " '00 hate',\n",
              " '00 head',\n",
              " '00 headed',\n",
              " '00 hear',\n",
              " '00 heard',\n",
              " '00 hee',\n",
              " '00 heh',\n",
              " '00 hello',\n",
              " '00 help',\n",
              " '00 hit',\n",
              " '00 hm',\n",
              " '00 hmm',\n",
              " '00 hold',\n",
              " '00 home',\n",
              " '00 honestly',\n",
              " '00 hope',\n",
              " '00 hopefully',\n",
              " '00 hopes',\n",
              " '00 hoping',\n",
              " '00 horrible',\n",
              " '00 hot',\n",
              " '00 hour',\n",
              " '00 howard',\n",
              " '00 hr',\n",
              " '00 htm',\n",
              " '00 html',\n",
              " '00 hubby',\n",
              " '00 huge',\n",
              " '00 humidity',\n",
              " '00 hung',\n",
              " '00 hurry',\n",
              " '00 ice',\n",
              " '00 idk',\n",
              " '00 illinois',\n",
              " '00 im',\n",
              " '00 impound',\n",
              " '00 including',\n",
              " '00 indi',\n",
              " '00 individual',\n",
              " '00 installing',\n",
              " '00 instead',\n",
              " '00 ipt',\n",
              " '00 ish',\n",
              " '00 island',\n",
              " '00 item',\n",
              " '00 ive',\n",
              " '00 james',\n",
              " '00 jason',\n",
              " '00 jeff',\n",
              " '00 jennifer',\n",
              " '00 jesse',\n",
              " '00 joann',\n",
              " '00 joke',\n",
              " '00 josh',\n",
              " '00 july',\n",
              " '00 jump',\n",
              " '00 june',\n",
              " '00 karen',\n",
              " '00 ked',\n",
              " '00 keep',\n",
              " '00 keeping',\n",
              " '00 kept',\n",
              " '00 kev',\n",
              " '00 kind',\n",
              " '00 kinda',\n",
              " '00 kirsty',\n",
              " '00 kisses',\n",
              " '00 kitten',\n",
              " '00 knew',\n",
              " '00 knighting',\n",
              " '00 knock',\n",
              " '00 know',\n",
              " '00 kristi',\n",
              " '00 last',\n",
              " '00 lasted',\n",
              " '00 late',\n",
              " '00 later',\n",
              " '00 latest',\n",
              " '00 lay',\n",
              " '00 layed',\n",
              " '00 lb',\n",
              " '00 learn',\n",
              " '00 leave',\n",
              " '00 leaving',\n",
              " '00 left',\n",
              " '00 less',\n",
              " '00 let',\n",
              " '00 lets',\n",
              " '00 leukemia',\n",
              " '00 levi',\n",
              " '00 library',\n",
              " '00 licence',\n",
              " '00 lied',\n",
              " '00 life',\n",
              " '00 like',\n",
              " '00 lil',\n",
              " '00 limit',\n",
              " '00 lipstick',\n",
              " '00 list',\n",
              " '00 listed',\n",
              " '00 listen',\n",
              " '00 little',\n",
              " '00 live',\n",
              " '00 long',\n",
              " '00 longer',\n",
              " '00 looked',\n",
              " '00 looks',\n",
              " '00 lost',\n",
              " '00 love',\n",
              " '00 lovin',\n",
              " '00 lp',\n",
              " '00 lucky',\n",
              " '00 lugar',\n",
              " '00 luke',\n",
              " '00 lump',\n",
              " '00 lunch',\n",
              " '00 lunchtime',\n",
              " '00 mad',\n",
              " '00 made',\n",
              " '00 madsh00ter',\n",
              " '00 major',\n",
              " '00 make',\n",
              " '00 makes',\n",
              " '00 man',\n",
              " '00 marching',\n",
              " '00 marissa',\n",
              " '00 mark',\n",
              " '00 marked',\n",
              " '00 matter',\n",
              " '00 mayan',\n",
              " '00 maybe',\n",
              " '00 mean',\n",
              " '00 means',\n",
              " '00 meet',\n",
              " '00 meeting',\n",
              " '00 mentally',\n",
              " '00 mention',\n",
              " '00 mercedes',\n",
              " '00 merchant',\n",
              " '00 message',\n",
              " '00 met',\n",
              " '00 mid',\n",
              " '00 midday',\n",
              " '00 midnight',\n",
              " '00 might',\n",
              " '00 mike',\n",
              " '00 mine',\n",
              " '00 ministry',\n",
              " '00 minute',\n",
              " '00 minutes',\n",
              " '00 miscellaneous',\n",
              " '00 missed',\n",
              " '00 mission',\n",
              " '00 mixed',\n",
              " '00 modernity',\n",
              " '00 mom',\n",
              " '00 month',\n",
              " '00 monty',\n",
              " '00 morning',\n",
              " '00 mostly',\n",
              " '00 motel',\n",
              " '00 mountain',\n",
              " '00 movie',\n",
              " '00 movies',\n",
              " '00 moving',\n",
              " '00 mrs',\n",
              " '00 much',\n",
              " '00 music',\n",
              " '00 must',\n",
              " '00 name',\n",
              " '00 nana',\n",
              " '00 naomi',\n",
              " '00 nap',\n",
              " '00 nasty',\n",
              " '00 natasha',\n",
              " '00 nathan',\n",
              " '00 nbc',\n",
              " '00 nbsp',\n",
              " '00 nederland',\n",
              " '00 need',\n",
              " '00 negotiation',\n",
              " '00 neil',\n",
              " '00 neopet',\n",
              " '00 never',\n",
              " '00 new',\n",
              " '00 newton',\n",
              " '00 next',\n",
              " '00 nice',\n",
              " '00 night',\n",
              " '00 nightly',\n",
              " '00 nights',\n",
              " '00 nominate',\n",
              " '00 non',\n",
              " '00 noon',\n",
              " '00 nortel',\n",
              " '00 note',\n",
              " '00 nuthingspeshul',\n",
              " '00 offer',\n",
              " '00 office',\n",
              " '00 oh',\n",
              " '00 oi',\n",
              " '00 ok',\n",
              " '00 okay',\n",
              " '00 older',\n",
              " '00 olivia',\n",
              " '00 one',\n",
              " '00 online',\n",
              " '00 oops',\n",
              " '00 open',\n",
              " '00 opening',\n",
              " '00 order',\n",
              " '00 ordered',\n",
              " '00 original',\n",
              " '00 ouch',\n",
              " '00 owwwwww',\n",
              " '00 pacific',\n",
              " '00 package',\n",
              " '00 panera',\n",
              " '00 parents',\n",
              " '00 parked',\n",
              " '00 part',\n",
              " '00 party',\n",
              " '00 passed',\n",
              " '00 passenger',\n",
              " '00 past',\n",
              " '00 patriotic',\n",
              " '00 pauanui',\n",
              " '00 pay',\n",
              " '00 paycheck',\n",
              " '00 payment',\n",
              " '00 pen',\n",
              " '00 people',\n",
              " '00 per',\n",
              " '00 perhaps',\n",
              " '00 person',\n",
              " '00 peter',\n",
              " '00 pick',\n",
              " '00 picked',\n",
              " '00 piece',\n",
              " '00 piss',\n",
              " '00 plan',\n",
              " '00 planet',\n",
              " '00 play',\n",
              " '00 played',\n",
              " '00 playing',\n",
              " '00 plaza',\n",
              " '00 pleased',\n",
              " '00 plus',\n",
              " '00 pm',\n",
              " '00 point',\n",
              " '00 polish',\n",
              " '00 poorer',\n",
              " '00 popcorn',\n",
              " '00 popped',\n",
              " '00 pps',\n",
              " '00 prada',\n",
              " '00 precise',\n",
              " '00 prep',\n",
              " '00 presentations',\n",
              " '00 pretty',\n",
              " '00 previously',\n",
              " '00 price',\n",
              " '00 prince',\n",
              " '00 printed',\n",
              " '00 probably',\n",
              " '00 program',\n",
              " '00 programming',\n",
              " '00 project',\n",
              " '00 promised',\n",
              " '00 proper',\n",
              " '00 pt',\n",
              " '00 public',\n",
              " '00 pull',\n",
              " '00 punkish',\n",
              " '00 put',\n",
              " '00 queer',\n",
              " '00 quickly',\n",
              " '00 quit',\n",
              " '00 quite',\n",
              " '00 race',\n",
              " '00 radio',\n",
              " '00 rain',\n",
              " '00 ralph',\n",
              " '00 ran',\n",
              " '00 rapuh',\n",
              " '00 rarely',\n",
              " '00 ravenwood',\n",
              " '00 ready',\n",
              " '00 real',\n",
              " '00 realistically',\n",
              " '00 realize',\n",
              " '00 realized',\n",
              " '00 really',\n",
              " '00 reason',\n",
              " '00 reawakened',\n",
              " '00 rebecca',\n",
              " '00 receipt',\n",
              " '00 recently',\n",
              " '00 recovery',\n",
              " '00 rediscovered',\n",
              " '00 regardless',\n",
              " '00 rehearsal',\n",
              " '00 rehearsals',\n",
              " '00 remeber',\n",
              " '00 remember',\n",
              " '00 rent',\n",
              " '00 repeat',\n",
              " '00 replied',\n",
              " '00 reservations',\n",
              " '00 resist',\n",
              " '00 rest',\n",
              " '00 return',\n",
              " '00 richie',\n",
              " '00 rides',\n",
              " '00 right',\n",
              " '00 ringing',\n",
              " '00 road',\n",
              " '00 rocks',\n",
              " '00 roll',\n",
              " '00 rolled',\n",
              " '00 romantic',\n",
              " '00 room',\n",
              " '00 running',\n",
              " '00 sac',\n",
              " '00 said',\n",
              " '00 sailed',\n",
              " '00 sale',\n",
              " '00 sales',\n",
              " '00 sang',\n",
              " '00 sarah',\n",
              " '00 sat',\n",
              " '00 saturdai',\n",
              " '00 saturday',\n",
              " '00 saved',\n",
              " '00 saving',\n",
              " '00 savings',\n",
              " '00 saw',\n",
              " '00 say',\n",
              " '00 saying',\n",
              " '00 sbristowsd6',\n",
              " '00 schedule',\n",
              " '00 school',\n",
              " '00 score',\n",
              " '00 scored',\n",
              " '00 searching',\n",
              " '00 sec',\n",
              " '00 security',\n",
              " '00 see',\n",
              " '00 selling',\n",
              " '00 send',\n",
              " '00 service',\n",
              " '00 session',\n",
              " '00 set',\n",
              " '00 sh',\n",
              " '00 shame',\n",
              " '00 sharp',\n",
              " '00 shaw',\n",
              " '00 shift',\n",
              " '00 shipping',\n",
              " '00 shit',\n",
              " '00 shitiest',\n",
              " '00 shoe',\n",
              " '00 shoes',\n",
              " '00 shopping',\n",
              " '00 short',\n",
              " '00 shortly',\n",
              " '00 shots',\n",
              " '00 show',\n",
              " '00 showed',\n",
              " '00 shower',\n",
              " '00 showing',\n",
              " '00 shucks',\n",
              " '00 side',\n",
              " '00 sigh',\n",
              " '00 simple',\n",
              " '00 since',\n",
              " '00 singing',\n",
              " '00 sky',\n",
              " '00 sleep',\n",
              " '00 sleeping',\n",
              " '00 sleepy',\n",
              " '00 slept',\n",
              " '00 smoked',\n",
              " '00 snooze',\n",
              " '00 snt',\n",
              " '00 socks',\n",
              " '00 someone',\n",
              " '00 something',\n",
              " '00 song',\n",
              " '00 soon',\n",
              " '00 sooo',\n",
              " '00 soooooo',\n",
              " '00 speak',\n",
              " '00 specific',\n",
              " '00 speeding',\n",
              " '00 spend',\n",
              " '00 spent',\n",
              " '00 sponsor',\n",
              " '00 sq',\n",
              " '00 started',\n",
              " '00 starting',\n",
              " '00 stayed',\n",
              " '00 sticks',\n",
              " '00 still',\n",
              " '00 stocked',\n",
              " '00 stole',\n",
              " '00 stolen',\n",
              " '00 stood',\n",
              " '00 stopped',\n",
              " '00 strength',\n",
              " '00 student',\n",
              " '00 students',\n",
              " '00 studies',\n",
              " '00 stuff',\n",
              " '00 stupid',\n",
              " '00 subject',\n",
              " '00 sucks',\n",
              " '00 sumber',\n",
              " '00 summer',\n",
              " '00 sunday',\n",
              " '00 supposed',\n",
              " '00 sure',\n",
              " '00 suspect',\n",
              " '00 tacks',\n",
              " '00 take',\n",
              " '00 takes',\n",
              " '00 talked',\n",
              " '00 talks',\n",
              " '00 technically',\n",
              " '00 teh',\n",
              " '00 tennessee',\n",
              " '00 tent',\n",
              " '00 thank',\n",
              " '00 thanks',\n",
              " '00 thats',\n",
              " '00 think',\n",
              " '00 though',\n",
              " '00 thought',\n",
              " '00 three',\n",
              " '00 threw',\n",
              " '00 throw',\n",
              " '00 thu',\n",
              " '00 thunderstorm',\n",
              " '00 thursday',\n",
              " '00 thursdays',\n",
              " '00 ticket',\n",
              " '00 tickets',\n",
              " '00 til',\n",
              " '00 till',\n",
              " '00 time',\n",
              " '00 tips',\n",
              " '00 tired',\n",
              " '00 today',\n",
              " '00 todays',\n",
              " '00 told',\n",
              " '00 toledo',\n",
              " '00 tomorrow',\n",
              " '00 tonight',\n",
              " '00 took',\n",
              " '00 top',\n",
              " '00 total',\n",
              " '00 tough',\n",
              " '00 track',\n",
              " '00 trade',\n",
              " '00 travision',\n",
              " '00 tribal',\n",
              " '00 tried',\n",
              " '00 truck',\n",
              " '00 true',\n",
              " '00 try',\n",
              " '00 trying',\n",
              " '00 tue',\n",
              " '00 tuesday',\n",
              " '00 tuesdays',\n",
              " '00 tv',\n",
              " '00 two',\n",
              " '00 ugh',\n",
              " '00 uh',\n",
              " '00 und',\n",
              " '00 unhealthy',\n",
              " '00 unit',\n",
              " '00 update',\n",
              " '00 ups',\n",
              " '00 urllink',\n",
              " '00 us',\n",
              " '00 usd',\n",
              " '00 used',\n",
              " '00 usher',\n",
              " '00 usual',\n",
              " '00 usually',\n",
              " '00 value',\n",
              " '00 vic',\n",
              " '00 waffles',\n",
              " '00 wait',\n",
              " '00 waited',\n",
              " '00 waiting',\n",
              " '00 wake',\n",
              " '00 walk',\n",
              " '00 walked',\n",
              " '00 wall',\n",
              " '00 want',\n",
              " '00 wanted',\n",
              " '00 wasted',\n",
              " '00 watch',\n",
              " '00 watched',\n",
              " '00 watching',\n",
              " '00 water',\n",
              " '00 way',\n",
              " '00 web',\n",
              " '00 wed',\n",
              " '00 wednesday',\n",
              " '00 wednesdays',\n",
              " '00 week',\n",
              " '00 weekday',\n",
              " '00 weeknight',\n",
              " '00 well',\n",
              " '00 went',\n",
              " '00 whaddayadoing',\n",
              " '00 whatever',\n",
              " '00 whip',\n",
              " '00 wib',\n",
              " '00 wide',\n",
              " '00 win',\n",
              " '00 wish',\n",
              " '00 within',\n",
              " '00 woke',\n",
              " '00 woken',\n",
              " '00 wonderful',\n",
              " '00 woo',\n",
              " '00 woohoo',\n",
              " '00 work',\n",
              " '00 worked',\n",
              " '00 working',\n",
              " '00 works',\n",
              " '00 worldcom',\n",
              " '00 worrying',\n",
              " '00 worth',\n",
              " '00 would',\n",
              " '00 wraps',\n",
              " '00 write',\n",
              " '00 wuz',\n",
              " '00 yay',\n",
              " '00 yeah',\n",
              " '00 years',\n",
              " '00 yeeeha',\n",
              " '00 yelled',\n",
              " '00 yep',\n",
              " '00 yes',\n",
              " '00 yesterday',\n",
              " '00 yet',\n",
              " '00 yipppeeeeeeeeeeeee',\n",
              " '00 yummy',\n",
              " '00 yup',\n",
              " '000',\n",
              " '000 00',\n",
              " '000 000',\n",
              " '000 06',\n",
              " '000 10',\n",
              " '000 100',\n",
              " '000 11',\n",
              " '000 12',\n",
              " '000 120',\n",
              " '000 14',\n",
              " '000 15',\n",
              " '000 1856',\n",
              " '000 1998',\n",
              " '000 20',\n",
              " '000 200',\n",
              " '000 25',\n",
              " '000 250',\n",
              " '000 26',\n",
              " '000 31',\n",
              " '000 34',\n",
              " '000 35',\n",
              " '000 36',\n",
              " '000 40',\n",
              " '000 400',\n",
              " '000 43',\n",
              " '000 435usd',\n",
              " '000 46',\n",
              " '000 50',\n",
              " '000 500',\n",
              " '000 50usd',\n",
              " '000 600usd',\n",
              " '000 65',\n",
              " '000 72',\n",
              " '000 7usd',\n",
              " '000 999',\n",
              " '000 __________________',\n",
              " '000 able',\n",
              " '000 abstracts',\n",
              " '000 accomplishment',\n",
              " '000 accounts',\n",
              " '000 acre',\n",
              " '000 acres',\n",
              " '000 active',\n",
              " '000 actually',\n",
              " '000 added',\n",
              " '000 addition',\n",
              " '000 additional',\n",
              " '000 address',\n",
              " '000 afternoon',\n",
              " '000 ah',\n",
              " '000 air',\n",
              " '000 akiane',\n",
              " '000 albums',\n",
              " '000 alex',\n",
              " '000 allied',\n",
              " '000 already',\n",
              " '000 also',\n",
              " '000 american',\n",
              " '000 americans',\n",
              " '000 amish',\n",
              " '000 amp',\n",
              " '000 animals',\n",
              " '000 annual',\n",
              " '000 annually',\n",
              " '000 anything',\n",
              " '000 appeals',\n",
              " '000 applications',\n",
              " '000 april',\n",
              " '000 armored',\n",
              " '000 athletes',\n",
              " '000 attack',\n",
              " '000 attend',\n",
              " '000 automobile',\n",
              " '000 available',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMKpC91xnW_P"
      },
      "source": [
        "x_train_trans = convec.transform(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vrxQkLknkL3",
        "outputId": "87413223-1e0a-4d29-d987-14596f77a98f"
      },
      "source": [
        "type(x_train_trans)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y14dMvhZnooA",
        "outputId": "f2d53bf8-2e07-403d-8a39-84d5a80c8e71"
      },
      "source": [
        "x_train_trans"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<80000x4262296 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 13669695 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTztyr-NnolK",
        "outputId": "f7d949da-4602-475d-bb92-1b776178d6d5"
      },
      "source": [
        "x_train_trans[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x4262296 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 39 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bQQ2keAnoLU"
      },
      "source": [
        "x_test_trans = convec.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGdD8LsCnoIa",
        "outputId": "38abc776-ceef-4c78-ab47-f563123ca2b3"
      },
      "source": [
        "x_test_trans"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<20000x4262296 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 2555765 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9iPjZXGnoEk",
        "outputId": "ee8f2254-c150-4d7e-b925-2c40323af084"
      },
      "source": [
        "convec.get_feature_names()[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00',\n",
              " '00 00',\n",
              " '00 000',\n",
              " '00 00a',\n",
              " '00 00am',\n",
              " '00 01',\n",
              " '00 03',\n",
              " '00 04',\n",
              " '00 05',\n",
              " '00 07']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn_cmLI7oKmY",
        "outputId": "ea22c4a2-3cd3-4c82-8cc0-37cfca6bbb5c"
      },
      "source": [
        "print(x_train_trans)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 280126)\t1\n",
            "  (0, 281571)\t1\n",
            "  (0, 656747)\t1\n",
            "  (0, 656764)\t1\n",
            "  (0, 767770)\t1\n",
            "  (0, 769071)\t1\n",
            "  (0, 1481476)\t1\n",
            "  (0, 1481650)\t1\n",
            "  (0, 1545997)\t1\n",
            "  (0, 1550942)\t1\n",
            "  (0, 1798724)\t1\n",
            "  (0, 2097555)\t1\n",
            "  (0, 2100025)\t1\n",
            "  (0, 2512992)\t1\n",
            "  (0, 2514598)\t1\n",
            "  (0, 2627012)\t1\n",
            "  (0, 2628742)\t1\n",
            "  (0, 2638718)\t1\n",
            "  (0, 2638926)\t1\n",
            "  (0, 2781087)\t1\n",
            "  (0, 2781417)\t1\n",
            "  (0, 2927984)\t1\n",
            "  (0, 2928046)\t1\n",
            "  (0, 3199369)\t1\n",
            "  (0, 3202000)\t1\n",
            "  :\t:\n",
            "  (79999, 3425683)\t1\n",
            "  (79999, 3548988)\t1\n",
            "  (79999, 3549426)\t1\n",
            "  (79999, 3559880)\t1\n",
            "  (79999, 3560675)\t1\n",
            "  (79999, 3570390)\t1\n",
            "  (79999, 3570430)\t1\n",
            "  (79999, 3618805)\t1\n",
            "  (79999, 3618823)\t1\n",
            "  (79999, 3622576)\t1\n",
            "  (79999, 3622581)\t1\n",
            "  (79999, 3661457)\t1\n",
            "  (79999, 3662790)\t1\n",
            "  (79999, 3853798)\t1\n",
            "  (79999, 3853811)\t1\n",
            "  (79999, 3891594)\t1\n",
            "  (79999, 3891611)\t1\n",
            "  (79999, 3905006)\t1\n",
            "  (79999, 3905007)\t1\n",
            "  (79999, 4002832)\t1\n",
            "  (79999, 4002834)\t1\n",
            "  (79999, 4200082)\t1\n",
            "  (79999, 4200688)\t1\n",
            "  (79999, 4206128)\t1\n",
            "  (79999, 4206297)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl_0IwU7oP20",
        "outputId": "5f95cf20-a58d-4bb1-ae25-3e6974ac0445"
      },
      "source": [
        "print(x_test_trans)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 27426)\t1\n",
            "  (0, 79796)\t1\n",
            "  (0, 80057)\t1\n",
            "  (0, 80555)\t1\n",
            "  (0, 81375)\t1\n",
            "  (0, 115114)\t1\n",
            "  (0, 142985)\t1\n",
            "  (0, 152758)\t1\n",
            "  (0, 152824)\t1\n",
            "  (0, 180482)\t1\n",
            "  (0, 181152)\t1\n",
            "  (0, 192557)\t1\n",
            "  (0, 193171)\t1\n",
            "  (0, 225481)\t1\n",
            "  (0, 226359)\t1\n",
            "  (0, 246204)\t1\n",
            "  (0, 271835)\t3\n",
            "  (0, 271883)\t1\n",
            "  (0, 272842)\t1\n",
            "  (0, 272879)\t1\n",
            "  (0, 290370)\t1\n",
            "  (0, 290382)\t1\n",
            "  (0, 355658)\t1\n",
            "  (0, 364270)\t1\n",
            "  (0, 646905)\t2\n",
            "  :\t:\n",
            "  (19999, 3733388)\t1\n",
            "  (19999, 3782530)\t1\n",
            "  (19999, 3787033)\t1\n",
            "  (19999, 3794952)\t1\n",
            "  (19999, 3808100)\t1\n",
            "  (19999, 3869260)\t1\n",
            "  (19999, 3873946)\t1\n",
            "  (19999, 3874156)\t1\n",
            "  (19999, 3910739)\t1\n",
            "  (19999, 3910831)\t1\n",
            "  (19999, 3914798)\t1\n",
            "  (19999, 3915766)\t1\n",
            "  (19999, 3938744)\t2\n",
            "  (19999, 3939435)\t1\n",
            "  (19999, 3957383)\t1\n",
            "  (19999, 3959374)\t1\n",
            "  (19999, 3969746)\t1\n",
            "  (19999, 3995987)\t1\n",
            "  (19999, 4035852)\t2\n",
            "  (19999, 4037932)\t1\n",
            "  (19999, 4037993)\t1\n",
            "  (19999, 4047826)\t1\n",
            "  (19999, 4115742)\t1\n",
            "  (19999, 4152425)\t1\n",
            "  (19999, 4153320)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6nDbvPDoTO-"
      },
      "source": [
        "label_counts=dict()\n",
        "\n",
        "for labels in df_new.labels.values:\n",
        "    for label in labels:\n",
        "        if label in label_counts:\n",
        "            label_counts[str(label)]+=1\n",
        "        else:\n",
        "            label_counts[str(label)]=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhc_x8Lcq7HR"
      },
      "source": [
        "Create a dictionary to get the count of every label i.e. the key will be label name and value will be the total count of the label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TafeB7uIqi5a",
        "outputId": "d4919ed0-7aff-4b65-9102-92daa2b2c2da"
      },
      "source": [
        "label_counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'13': 1,\n",
              " '14': 1,\n",
              " '15': 1,\n",
              " '16': 1,\n",
              " '17': 1,\n",
              " '23': 1,\n",
              " '24': 1,\n",
              " '25': 1,\n",
              " '26': 1,\n",
              " '27': 1,\n",
              " '33': 1,\n",
              " '34': 1,\n",
              " '35': 1,\n",
              " '36': 1,\n",
              " '37': 1,\n",
              " '38': 1,\n",
              " '39': 1,\n",
              " '40': 1,\n",
              " '41': 1,\n",
              " '42': 1,\n",
              " '43': 1,\n",
              " '44': 1,\n",
              " '45': 1,\n",
              " '46': 1,\n",
              " '47': 1,\n",
              " '48': 1,\n",
              " 'Accounting': 528,\n",
              " 'Advertising': 766,\n",
              " 'Agriculture': 168,\n",
              " 'Aquarius': 9050,\n",
              " 'Architecture': 83,\n",
              " 'Aries': 10637,\n",
              " 'Arts': 5031,\n",
              " 'Automotive': 124,\n",
              " 'Banking': 354,\n",
              " 'Biotech': 324,\n",
              " 'BusinessServices': 626,\n",
              " 'Cancer': 9253,\n",
              " 'Capricorn': 8723,\n",
              " 'Chemicals': 305,\n",
              " 'Communications-Media': 2830,\n",
              " 'Construction': 250,\n",
              " 'Consulting': 905,\n",
              " 'Education': 5553,\n",
              " 'Engineering': 2332,\n",
              " 'Environment': 6,\n",
              " 'Fashion': 1898,\n",
              " 'Gemini': 9225,\n",
              " 'Government': 2055,\n",
              " 'HumanResources': 209,\n",
              " 'Internet': 2251,\n",
              " 'InvestmentBanking': 244,\n",
              " 'Law': 360,\n",
              " 'LawEnforcement-Security': 368,\n",
              " 'Leo': 8230,\n",
              " 'Libra': 7250,\n",
              " 'Manufacturing': 542,\n",
              " 'Maritime': 59,\n",
              " 'Marketing': 726,\n",
              " 'Military': 798,\n",
              " 'Museums-Libraries': 308,\n",
              " 'Non-Profit': 1326,\n",
              " 'Pisces': 7553,\n",
              " 'Publishing': 1079,\n",
              " 'RealEstate': 149,\n",
              " 'Religion': 1081,\n",
              " 'Sagittarius': 7366,\n",
              " 'Science': 1090,\n",
              " 'Scorpio': 7049,\n",
              " 'Sports-Recreation': 406,\n",
              " 'Student': 22122,\n",
              " 'Taurus': 8530,\n",
              " 'Technology': 8484,\n",
              " 'Telecommunications': 165,\n",
              " 'Tourism': 253,\n",
              " 'Transportation': 745,\n",
              " 'Virgo': 7134,\n",
              " 'female': 46642,\n",
              " 'indUnk': 33097,\n",
              " 'male': 53358}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcT2BDTDrXLc"
      },
      "source": [
        "## Transform the labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XstmgfJArbM2"
      },
      "source": [
        "As we have noticed before, in this task each example can have multiple tags. To deal with such kind of prediction, we need to transform labels in a binary form and the prediction will be a mask of 0s and 1s. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpsi7b98q1UO"
      },
      "source": [
        "binarizer = MultiLabelBinarizer(classes = sorted(label_counts.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAAcYSQErs8d",
        "outputId": "971e703c-044c-4681-a62e-1713da0ce8ac"
      },
      "source": [
        "y_train = binarizer.fit_transform(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:987: UserWarning: unknown class(es) [13, 14, 15, 16, 17, 23, 24, 25, 26, 27, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48] will be ignored\n",
            "  .format(sorted(unknown, key=str)))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tQpH3jCr2wz",
        "outputId": "bdc4a6d4-b998-42b3-c67e-e0e609148424"
      },
      "source": [
        "y_test = binarizer.transform(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:987: UserWarning: unknown class(es) [13, 14, 15, 16, 17, 23, 24, 25, 26, 27, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48] will be ignored\n",
            "  .format(sorted(unknown, key=str)))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V68qxQAosNTW",
        "outputId": "6a78bfd9-b5fb-4464-e218-b02bd2b5fd99"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 1, 1, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD8JlqwDsQZN",
        "outputId": "8c76f8cd-83dd-42f9-cebd-c099109ff4a5"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 1, 1, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBjo-mCl0rJ7"
      },
      "source": [
        "## **3. Design, train, tune and test the best text classifier.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivPnKeEEsRDF",
        "outputId": "28326975-795d-4d4d-e2dd-6176f1c04363"
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(solver = 'lbfgs', max_iter = 500000)\n",
        "model = OneVsRestClassifier(model)\n",
        "model.fit(x_train_trans, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 0 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 1 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 2 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 3 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 4 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 5 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 6 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 7 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 8 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 9 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 10 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 11 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 12 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 13 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 14 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 15 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 16 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 17 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 18 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 19 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 20 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 21 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 22 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 23 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 24 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 25 is present in all training examples.\n",
            "  str(classes[c]))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                 dual=False, fit_intercept=True,\n",
              "                                                 intercept_scaling=1,\n",
              "                                                 l1_ratio=None, max_iter=500000,\n",
              "                                                 multi_class='auto',\n",
              "                                                 n_jobs=None, penalty='l2',\n",
              "                                                 random_state=None,\n",
              "                                                 solver='lbfgs', tol=0.0001,\n",
              "                                                 verbose=0, warm_start=False),\n",
              "                    n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "q0eOGq8M1Vn0"
      },
      "source": [
        "ypred = model.predict(x_test_trans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MDNBMzwFVIYX",
        "outputId": "4b4b2884-ebdb-4b6a-aa02-b1ef663adc54"
      },
      "source": [
        "ypred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 1, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xz9YIH3YVH79",
        "outputId": "90d331df-6b0f-4a2b-860d-baa3f8771f4b"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 1, 1, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pUJPp6nQSnf"
      },
      "source": [
        "## **Micro-average method :**\n",
        "\n",
        "you sum up the individual true positives, false positives, and false negatives of the system for different sets and the apply them to get the statistics.\n",
        "\n",
        "## **Macro-average Method :**\n",
        "The method is straight forward. Just take the average of the precision and recall of the system on different sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_CFH4fKBVHsa"
      },
      "source": [
        "def display_metrics_micro(y_test, ypred):\n",
        "    print('Accuracy score: ', accuracy_score(y_test, ypred))\n",
        "    print('F1 score: Micro', f1_score(y_test, ypred, average='micro'))\n",
        "    print('Average precision score: Micro', average_precision_score(y_test, ypred, average='micro'))\n",
        "    print('Average recall score: Micro', recall_score(y_test, ypred, average='micro'))\n",
        "    \n",
        "    \n",
        "def display_metrics_macro(y_test, ypred):\n",
        "    print('Accuracy score: ', accuracy_score(y_test, ypred))\n",
        "    print('F1 score: Macro', f1_score(y_test, ypred, average='macro'))\n",
        "    print('Average recall score: MAcro', recall_score(y_test, ypred, average='macro'))\n",
        "    \n",
        "def display_metrics_weighted(y_test, ypred):\n",
        "    print('Accuracy score: ', accuracy_score(y_test, ypred))\n",
        "    print('F1 score: weighted', f1_score(y_test, ypred, average='weighted'))\n",
        "    print('Average precision score: weighted', average_precision_score(y_test, ypred, average='weighted'))\n",
        "    print('Average recall score: weighted', recall_score(y_test, ypred, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v4OkSk_GVHeE",
        "outputId": "7be6f720-11b4-440c-ea3f-b161562edaa6"
      },
      "source": [
        "display_metrics_micro(y_test, ypred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.1164\n",
            "F1 score: Micro 0.4817371003751176\n",
            "Average precision score: Micro 0.2908289227811419\n",
            "Average recall score: Micro 0.35423333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DwWDYFZKVHbQ",
        "outputId": "6422bc04-a0ed-4b15-cf41-fd8fade38d5b"
      },
      "source": [
        "display_metrics_macro(y_test, ypred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.1164\n",
            "F1 score: Macro 0.1678094304601543\n",
            "Average recall score: MAcro 0.1117599498017056\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-hxCay3XVHW4",
        "outputId": "df085bac-224f-4cad-c32c-2342c937113c"
      },
      "source": [
        "display_metrics_weighted(y_test, ypred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.1164\n",
            "F1 score: weighted 0.4448969920386379\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:677: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = tps / tps[-1]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average precision score: weighted 0.39193212328684823\n",
            "Average recall score: weighted 0.35423333333333334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjlVIzRNR-lq"
      },
      "source": [
        "## **5. Print the true vs predicted labels for any 5 entries from the dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2LmhYSpxQzx_"
      },
      "source": [
        "preds = ypred[:15]\n",
        "actuals = y_test[:15]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_FOqGnLQTInG",
        "outputId": "c60451c7-0d4e-4c30-dc48-1e13ada06e6b"
      },
      "source": [
        "five_actual = binarizer.inverse_transform(actuals)\n",
        "five_actual"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Aquarius', 'Education', 'male'),\n",
              " ('Pisces', 'Student', 'male'),\n",
              " ('Pisces', 'female', 'indUnk'),\n",
              " ('Aquarius', 'Non-Profit', 'female'),\n",
              " ('Arts', 'Cancer', 'male'),\n",
              " ('Scorpio', 'female', 'indUnk'),\n",
              " ('Cancer', 'Student', 'male'),\n",
              " ('Gemini', 'indUnk', 'male'),\n",
              " ('Scorpio', 'Technology', 'male'),\n",
              " ('Cancer', 'indUnk', 'male'),\n",
              " ('Pisces', 'Technology', 'male'),\n",
              " ('Gemini', 'Student', 'female'),\n",
              " ('Student', 'Virgo', 'male'),\n",
              " ('Cancer', 'indUnk', 'male'),\n",
              " ('Libra', 'female', 'indUnk')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1xvhSlRjTMz0",
        "outputId": "ab515a47-ebd7-4398-da8a-a85cec1a066e"
      },
      "source": [
        "five_pred = binarizer.inverse_transform(preds)\n",
        "five_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Aquarius', 'Education', 'male'),\n",
              " ('male',),\n",
              " ('male',),\n",
              " (),\n",
              " ('Non-Profit', 'male'),\n",
              " (),\n",
              " (),\n",
              " ('Internet', 'Leo', 'male'),\n",
              " ('male',),\n",
              " ('Scorpio', 'Student', 'male'),\n",
              " (),\n",
              " ('male',),\n",
              " ('Student', 'Virgo'),\n",
              " ('male',),\n",
              " ()]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zJ08VnBiTUsk",
        "outputId": "d172fa55-a804-4392-8635-be0ad1ba10cd"
      },
      "source": [
        "print(binarizer.inverse_transform(ypred)[100])\n",
        "print(binarizer.inverse_transform(y_test)[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Student', 'female')\n",
            "('Capricorn', 'Student', 'female')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-rALuyQ1TmPg",
        "outputId": "42338fc8-084e-4321-f640-7d467f5fd4b1"
      },
      "source": [
        "print(binarizer.inverse_transform(ypred)[250])\n",
        "print(binarizer.inverse_transform(y_test)[250])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Pisces', 'female', 'indUnk')\n",
            "('Pisces', 'female', 'indUnk')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "otgEqCZOTpLC",
        "outputId": "c02390d8-20fb-4d4d-c370-25fff1d4c4e6"
      },
      "source": [
        "print(binarizer.inverse_transform(ypred)[75])\n",
        "print(binarizer.inverse_transform(y_test)[75])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Scorpio', 'Technology', 'male')\n",
            "('Sagittarius', 'Technology', 'male')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "037FCIjgTp60",
        "outputId": "c0ca8384-7a85-4a85-c297-1cb1805bba4d"
      },
      "source": [
        "print(binarizer.inverse_transform(ypred)[299])\n",
        "print(binarizer.inverse_transform(y_test)[299])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Aquarius', 'indUnk', 'male')\n",
            "('Aquarius', 'indUnk', 'male')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "l9_kkTNvTp1w",
        "outputId": "b03a875b-f4d3-41aa-8a01-e51596effd12"
      },
      "source": [
        "print(binarizer.inverse_transform(ypred)[699])\n",
        "print(binarizer.inverse_transform(y_test)[699])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Aquarius', 'Marketing', 'female')\n",
            "('Aquarius', 'Marketing', 'female')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4puOlU8MTpwc",
        "outputId": "b47c5c59-2ccd-4d45-c2ad-770c479416db"
      },
      "source": [
        "import random\n",
        "j=[]\n",
        "for i in range(5):\n",
        "    j.append(random.randint(300,len(ypred)))\n",
        "   \n",
        "print(j)\n",
        "\n",
        "for k in j:    \n",
        "    print(binarizer.inverse_transform(ypred)[k])\n",
        "    print(binarizer.inverse_transform(y_test)[k])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1606, 9886, 3194, 10883, 17913]\n",
            "('indUnk', 'male')\n",
            "('Gemini', 'Student', 'female')\n",
            "('male',)\n",
            "('Aries', 'Education', 'male')\n",
            "('male',)\n",
            "('Leo', 'female', 'indUnk')\n",
            "('male',)\n",
            "('Libra', 'Technology', 'male')\n",
            "('male',)\n",
            "('Scorpio', 'Student', 'male')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZCKw7kRdU1T1",
        "outputId": "a095bc4d-657a-4a00-d8b1-a6b5c0644608"
      },
      "source": [
        "ypred_inversed = binarizer.inverse_transform(ypred)\n",
        "y_test_inversed = binarizer.inverse_transform(y_test)\n",
        "for i in range(5):\n",
        "    print('Text:\\t{}\\nTrue labels:\\t{}\\nPredicted labels:\\t{}\\n\\n'.format(\n",
        "        x_test_trans[i],\n",
        "        ','.join(y_test_inversed[i]),\n",
        "        ','.join(ypred_inversed[i])\n",
        "    ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text:\t  (0, 27426)\t1\n",
            "  (0, 79796)\t1\n",
            "  (0, 80057)\t1\n",
            "  (0, 80555)\t1\n",
            "  (0, 81375)\t1\n",
            "  (0, 115114)\t1\n",
            "  (0, 142985)\t1\n",
            "  (0, 152758)\t1\n",
            "  (0, 152824)\t1\n",
            "  (0, 180482)\t1\n",
            "  (0, 181152)\t1\n",
            "  (0, 192557)\t1\n",
            "  (0, 193171)\t1\n",
            "  (0, 225481)\t1\n",
            "  (0, 226359)\t1\n",
            "  (0, 246204)\t1\n",
            "  (0, 271835)\t3\n",
            "  (0, 271883)\t1\n",
            "  (0, 272842)\t1\n",
            "  (0, 272879)\t1\n",
            "  (0, 290370)\t1\n",
            "  (0, 290382)\t1\n",
            "  (0, 355658)\t1\n",
            "  (0, 364270)\t1\n",
            "  (0, 646905)\t2\n",
            "  :\t:\n",
            "  (0, 3463105)\t1\n",
            "  (0, 3528636)\t1\n",
            "  (0, 3702692)\t1\n",
            "  (0, 3703054)\t1\n",
            "  (0, 3734817)\t1\n",
            "  (0, 3737387)\t1\n",
            "  (0, 3771284)\t1\n",
            "  (0, 3771578)\t1\n",
            "  (0, 3822062)\t1\n",
            "  (0, 3822413)\t1\n",
            "  (0, 3944259)\t2\n",
            "  (0, 3949679)\t1\n",
            "  (0, 3949939)\t1\n",
            "  (0, 3963663)\t1\n",
            "  (0, 3964477)\t1\n",
            "  (0, 3970572)\t1\n",
            "  (0, 3982784)\t1\n",
            "  (0, 4009054)\t1\n",
            "  (0, 4009148)\t1\n",
            "  (0, 4035852)\t1\n",
            "  (0, 4038061)\t1\n",
            "  (0, 4126257)\t1\n",
            "  (0, 4126295)\t4\n",
            "  (0, 4126320)\t1\n",
            "  (0, 4159477)\t1\n",
            "True labels:\tAquarius,Education,male\n",
            "Predicted labels:\tAquarius,Education,male\n",
            "\n",
            "\n",
            "Text:\t  (0, 143874)\t1\n",
            "  (0, 175289)\t1\n",
            "  (0, 177204)\t1\n",
            "  (0, 339367)\t1\n",
            "  (0, 342183)\t1\n",
            "  (0, 726405)\t1\n",
            "  (0, 932276)\t1\n",
            "  (0, 934558)\t1\n",
            "  (0, 1033018)\t1\n",
            "  (0, 1509102)\t2\n",
            "  (0, 1514538)\t1\n",
            "  (0, 1545997)\t1\n",
            "  (0, 1548600)\t1\n",
            "  (0, 1630031)\t1\n",
            "  (0, 1702501)\t1\n",
            "  (0, 1704134)\t1\n",
            "  (0, 1966040)\t1\n",
            "  (0, 2006282)\t1\n",
            "  (0, 2006695)\t1\n",
            "  (0, 2063953)\t1\n",
            "  (0, 2065126)\t1\n",
            "  (0, 2109477)\t1\n",
            "  (0, 2109993)\t1\n",
            "  (0, 2263560)\t1\n",
            "  (0, 2267507)\t1\n",
            "  (0, 2494590)\t1\n",
            "  (0, 2780659)\t1\n",
            "  (0, 2875257)\t1\n",
            "  (0, 2875702)\t1\n",
            "  (0, 3009079)\t1\n",
            "  (0, 3376961)\t1\n",
            "  (0, 3377783)\t1\n",
            "  (0, 3453882)\t1\n",
            "  (0, 3455225)\t1\n",
            "  (0, 3535091)\t1\n",
            "  (0, 3535451)\t1\n",
            "  (0, 3657701)\t1\n",
            "  (0, 3688097)\t2\n",
            "  (0, 3688255)\t1\n",
            "  (0, 3794952)\t1\n",
            "  (0, 3795272)\t1\n",
            "  (0, 3834800)\t1\n",
            "  (0, 3835108)\t1\n",
            "  (0, 4011132)\t1\n",
            "  (0, 4011695)\t1\n",
            "  (0, 4072928)\t1\n",
            "  (0, 4073202)\t1\n",
            "True labels:\tPisces,Student,male\n",
            "Predicted labels:\tmale\n",
            "\n",
            "\n",
            "Text:\t  (0, 45120)\t1\n",
            "  (0, 45778)\t1\n",
            "  (0, 80555)\t1\n",
            "  (0, 81105)\t1\n",
            "  (0, 132053)\t1\n",
            "  (0, 214610)\t1\n",
            "  (0, 215888)\t1\n",
            "  (0, 259723)\t2\n",
            "  (0, 260192)\t1\n",
            "  (0, 289615)\t1\n",
            "  (0, 306083)\t1\n",
            "  (0, 306136)\t1\n",
            "  (0, 317218)\t1\n",
            "  (0, 318501)\t1\n",
            "  (0, 330057)\t3\n",
            "  (0, 331294)\t1\n",
            "  (0, 334032)\t1\n",
            "  (0, 335160)\t1\n",
            "  (0, 339367)\t1\n",
            "  (0, 341792)\t1\n",
            "  (0, 400394)\t1\n",
            "  (0, 400532)\t1\n",
            "  (0, 412666)\t1\n",
            "  (0, 415271)\t1\n",
            "  (0, 417270)\t1\n",
            "  :\t:\n",
            "  (0, 3805741)\t1\n",
            "  (0, 3810304)\t1\n",
            "  (0, 3811360)\t1\n",
            "  (0, 3842165)\t1\n",
            "  (0, 3873946)\t1\n",
            "  (0, 3874493)\t1\n",
            "  (0, 3886254)\t1\n",
            "  (0, 3886562)\t1\n",
            "  (0, 3892632)\t2\n",
            "  (0, 3895744)\t1\n",
            "  (0, 3895784)\t1\n",
            "  (0, 3966709)\t1\n",
            "  (0, 3967695)\t1\n",
            "  (0, 4062051)\t1\n",
            "  (0, 4063879)\t1\n",
            "  (0, 4079311)\t1\n",
            "  (0, 4079899)\t1\n",
            "  (0, 4091439)\t1\n",
            "  (0, 4094198)\t1\n",
            "  (0, 4099067)\t1\n",
            "  (0, 4101075)\t1\n",
            "  (0, 4186185)\t1\n",
            "  (0, 4188860)\t1\n",
            "  (0, 4233074)\t1\n",
            "  (0, 4234427)\t1\n",
            "True labels:\tPisces,female,indUnk\n",
            "Predicted labels:\tmale\n",
            "\n",
            "\n",
            "Text:\t  (0, 0)\t1\n",
            "  (0, 531)\t1\n",
            "  (0, 66219)\t1\n",
            "  (0, 66255)\t1\n",
            "  (0, 69127)\t2\n",
            "  (0, 491291)\t1\n",
            "  (0, 491589)\t1\n",
            "  (0, 580127)\t2\n",
            "  (0, 748033)\t2\n",
            "  (0, 750952)\t1\n",
            "  (0, 815528)\t1\n",
            "  (0, 932276)\t1\n",
            "  (0, 935830)\t1\n",
            "  (0, 959746)\t1\n",
            "  (0, 1218062)\t1\n",
            "  (0, 1219017)\t1\n",
            "  (0, 1318298)\t1\n",
            "  (0, 1318445)\t1\n",
            "  (0, 1636638)\t1\n",
            "  (0, 1638783)\t1\n",
            "  (0, 1825175)\t2\n",
            "  (0, 2431269)\t1\n",
            "  (0, 2433930)\t1\n",
            "  (0, 2441723)\t1\n",
            "  (0, 2494590)\t2\n",
            "  :\t:\n",
            "  (0, 3264833)\t1\n",
            "  (0, 3333254)\t1\n",
            "  (0, 3336204)\t1\n",
            "  (0, 3453882)\t1\n",
            "  (0, 3455310)\t1\n",
            "  (0, 3791367)\t1\n",
            "  (0, 3791592)\t1\n",
            "  (0, 3794952)\t1\n",
            "  (0, 3820364)\t2\n",
            "  (0, 3820575)\t1\n",
            "  (0, 3821831)\t1\n",
            "  (0, 3841212)\t1\n",
            "  (0, 4026268)\t1\n",
            "  (0, 4026269)\t1\n",
            "  (0, 4052189)\t1\n",
            "  (0, 4054404)\t1\n",
            "  (0, 4129202)\t1\n",
            "  (0, 4130046)\t1\n",
            "  (0, 4175371)\t1\n",
            "  (0, 4176939)\t1\n",
            "  (0, 4186185)\t1\n",
            "  (0, 4190215)\t1\n",
            "  (0, 4229764)\t2\n",
            "  (0, 4230820)\t1\n",
            "  (0, 4232285)\t1\n",
            "True labels:\tAquarius,Non-Profit,female\n",
            "Predicted labels:\t\n",
            "\n",
            "\n",
            "Text:\t  (0, 139998)\t1\n",
            "  (0, 154679)\t1\n",
            "  (0, 155133)\t1\n",
            "  (0, 218287)\t4\n",
            "  (0, 218783)\t4\n",
            "  (0, 273589)\t1\n",
            "  (0, 379153)\t1\n",
            "  (0, 379154)\t1\n",
            "  (0, 525507)\t1\n",
            "  (0, 525785)\t1\n",
            "  (0, 642517)\t1\n",
            "  (0, 643269)\t1\n",
            "  (0, 724602)\t1\n",
            "  (0, 724664)\t1\n",
            "  (0, 752002)\t2\n",
            "  (0, 753562)\t2\n",
            "  (0, 923882)\t1\n",
            "  (0, 1357532)\t1\n",
            "  (0, 1360730)\t1\n",
            "  (0, 1454974)\t1\n",
            "  (0, 1707358)\t1\n",
            "  (0, 1707429)\t1\n",
            "  (0, 1784417)\t1\n",
            "  (0, 2105672)\t1\n",
            "  (0, 2105699)\t1\n",
            "  :\t:\n",
            "  (0, 3505408)\t1\n",
            "  (0, 3505847)\t1\n",
            "  (0, 3535091)\t2\n",
            "  (0, 3535794)\t1\n",
            "  (0, 3537451)\t1\n",
            "  (0, 3748153)\t1\n",
            "  (0, 3750180)\t1\n",
            "  (0, 3782530)\t1\n",
            "  (0, 3784826)\t1\n",
            "  (0, 3810304)\t1\n",
            "  (0, 3811391)\t1\n",
            "  (0, 3863593)\t1\n",
            "  (0, 3864055)\t1\n",
            "  (0, 4026268)\t1\n",
            "  (0, 4026881)\t1\n",
            "  (0, 4115420)\t2\n",
            "  (0, 4115562)\t2\n",
            "  (0, 4137902)\t5\n",
            "  (0, 4138065)\t5\n",
            "  (0, 4161607)\t5\n",
            "  (0, 4163602)\t5\n",
            "  (0, 4175371)\t1\n",
            "  (0, 4175482)\t1\n",
            "  (0, 4217985)\t1\n",
            "  (0, 4218131)\t1\n",
            "True labels:\tArts,Cancer,male\n",
            "Predicted labels:\tNon-Profit,male\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n_Ezb_3U6QR"
      },
      "source": [
        "## Use a linear classifier (LinearSVC is used in my file) wrap it up in OneVsRestClassifier to train it on every label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eo5TxivAU1P2"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "def build_model_train(x_train, y_train, x_valid=None, y_valid=None, C=1.0, model='lr'):\n",
        "    if model=='lr':\n",
        "        model = LogisticRegression(C=C, penalty='l1', dual=False, solver='liblinear', max_iter = 500000)\n",
        "        model = OneVsRestClassifier(model)\n",
        "        model.fit(x_train, y_train)\n",
        "    \n",
        "    elif model=='svm':\n",
        "        model = LinearSVC(C=C, penalty='l1', dual=False, loss='squared_hinge')\n",
        "        model = OneVsRestClassifier(model)\n",
        "        model.fit(x_train, y_train)\n",
        "    \n",
        "    elif model=='nbayes':\n",
        "        model = MultinomialNB(alpha=1.0)\n",
        "        model = OneVsRestClassifier(model)\n",
        "        model.fit(x_train, y_train)\n",
        "        \n",
        "    elif model=='lda':\n",
        "        model = LinearDiscriminantAnalysis(solver='svd')\n",
        "        model = OneVsRestClassifier(model)\n",
        "        model.fit(x_train, y_train)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNYIcIZWU1KJ"
      },
      "source": [
        "models = ['lr','svm','nbayes']\n",
        "for model in models:\n",
        "    model = build_model_train(x_train_trans, y_train, model=model)\n",
        "    model.fit(x_train_trans, y_train)\n",
        "    ypred = model.predict(x_test_trans)\n",
        "    print(\"\\n\")\n",
        "    print(f\"**displaying  metrics for the mode {model}\\n\")\n",
        "    display_metrics_micro(y_test,ypred)\n",
        "    print(\"\\n\")\n",
        "    print(\"\\n\")\n",
        "    display_metrics_macro(y_test,ypred)\n",
        "    print(\"\\n\")\n",
        "    print(\"\\n\")\n",
        "    display_metrics_weighted(y_test,ypred)\n",
        "    print(\"\\n\")\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tna4VkYZjsot"
      },
      "source": [
        "# **2. PART TWO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC6uu5ZrtL_N",
        "outputId": "ca6c8a36-c8d4-4b77-f884-483b38039d7d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "mfZg8eTctL_O",
        "outputId": "2cfeb4b6-f1e1-4e47-cf13-3bced793d1a7"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wRByJ0ZtL_O"
      },
      "source": [
        "project_path = '/content/drive/MyDrive/My Files/AIML Workbooks'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsNhO-lPkRd4",
        "outputId": "492eb21f-7cd7-4a08-82e1-c2e53499f058"
      },
      "source": [
        "# Importing necessary libraries \n",
        "\n",
        "import string\n",
        "import random \n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import Sequential \n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from nltk.chat.util import Chat, reflections\n",
        "import tensorflow as tf\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AJl-a9UpDPP",
        "outputId": "878039a8-532b-4388-c9cf-5c93a2ecee28"
      },
      "source": [
        "# Loading corpus file\n",
        "\n",
        "import json\n",
        "with open('/content/drive/MyDrive/My Files/AIML Workbooks/GL Bot.json') as file:\n",
        "  Corpus = json.load(file)\n",
        "print(Corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'intents': [{'tag': 'Intro', 'patterns': ['hi', 'how are you', 'is anyone there', 'hello', 'whats up', 'hey', 'yo', 'listen', 'please help me', 'i am learner from', 'i belong to', 'aiml batch', 'aifl batch', 'i am from', 'my pm is', 'blended', 'online', 'i am from', 'hey ya', 'talking to you for first time'], 'responses': ['Hello! how can i help you ?'], 'context_set': ''}, {'tag': 'Exit', 'patterns': ['thank you', 'thanks', 'cya', 'see you', 'later', 'see you later', 'goodbye', 'i am leaving', 'have a Good day', 'you helped me', 'thanks a lot', 'thanks a ton', 'you are the best', 'great help', 'too good', 'you are a good learning buddy'], 'responses': ['I hope I was able to assist you, Good Bye'], 'context_set': ''}, {'tag': 'Olympus', 'patterns': ['olympus', 'explain me how olympus works', 'I am not able to understand olympus', 'olympus window not working', 'no access to olympus', 'unable to see link in olympus', 'no link visible on olympus', 'whom to contact for olympus', 'lot of problem with olympus', 'olypus is not a good tool', 'lot of problems with olympus', 'how to use olympus', 'teach me olympus'], 'responses': ['Link: Olympus wiki'], 'context_set': ''}, {'tag': 'SL', 'patterns': ['i am not able to understand svm', 'explain me how machine learning works', 'i am not able to understand naive bayes', 'i am not able to understand logistic regression', 'i am not able to understand ensemble techb=niques', 'i am not able to understand knn', 'i am not able to understand knn imputer', 'i am not able to understand cross validation', 'i am not able to understand boosting', 'i am not able to understand random forest', 'i am not able to understand ada boosting', 'i am not able to understand gradient boosting', 'machine learning', 'ML', 'SL', 'supervised learning', 'knn', 'logistic regression', 'regression', 'classification', 'naive bayes', 'nb', 'ensemble techniques', 'bagging', 'boosting', 'ada boosting', 'ada', 'gradient boosting', 'hyper parameters'], 'responses': ['Link: Machine Learning wiki '], 'context_set': ''}, {'tag': 'NN', 'patterns': ['what is deep learning', 'unable to understand deep learning', 'explain me how deep learning works', 'i am not able to understand deep learning', 'not able to understand neural nets', 'very diffult to understand neural nets', 'unable to understand neural nets', 'ann', 'artificial intelligence', 'artificial neural networks', 'weights', 'activation function', 'hidden layers', 'softmax', 'sigmoid', 'relu', 'otimizer', 'forward propagation', 'backward propagation', 'epochs', 'epoch', 'what is an epoch', 'adam', 'sgd'], 'responses': ['Link: Neural Nets wiki'], 'context_set': ''}, {'tag': 'Bot', 'patterns': ['what is your name', 'who are you', 'name please', 'when are your hours of opertions', 'what are your working hours', 'hours of operation', 'working hours', 'hours'], 'responses': ['I am your virtual learning assistant'], 'context_set': ''}, {'tag': 'Profane', 'patterns': ['what the hell', 'bloody stupid bot', 'do you think you are very smart', 'screw you', 'i hate you', 'you are stupid', 'jerk', 'you are a joke', 'useless piece of shit'], 'responses': ['Please use respectful words'], 'context_set': ''}, {'tag': 'Ticket', 'patterns': ['my problem is not solved', 'you did not help me', 'not a good solution', 'bad solution', 'not good solution', 'no help', 'wasted my time', 'useless bot', 'create a ticket'], 'responses': ['Tarnsferring the request to your PM'], 'context_set': ''}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC_bb9y7f00_"
      },
      "source": [
        "# initializing lemmatizer to get stem of words\n",
        "lem = WordNetLemmatizer()\n",
        "\n",
        "# Each list to create\n",
        "words = []\n",
        "classes = []\n",
        "doc_x = []\n",
        "doc_y = []\n",
        "\n",
        "# Loop through all the intents\n",
        "# Tokenize each pattern and append tokens to words, the patterns and the associated tag to their associated list\n",
        "\n",
        "for intent in Corpus ['intents']:\n",
        "  for pattern in intent['patterns']:\n",
        "    tokens = nltk.word_tokenize(pattern)\n",
        "    words.extend(tokens)\n",
        "    doc_x.append(pattern)\n",
        "    doc_y.append(intent['tag'])\n",
        "\n",
        "    # Add tag to classes if it is not present already \n",
        "    if intent['tag'] not in classes:\n",
        "      classes.append(intent['tag'])\n",
        "\n",
        "# lemmatize all the words in the vocab and convert them to lowercase if the words don't appear in punctuation\n",
        "words = [lem.lemmatize(word.lower()) for word in words if word not in string.punctuation]\n",
        "\n",
        "# sorting the vocab and classes in alphabetical order and taking the # set to ensure no duplicates occur\n",
        "words = sorted(set(words))\n",
        "classes = sorted(set(classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy4P_4fKjg8b",
        "outputId": "13181753-bdfc-43d1-c28a-17ede8ce309f"
      },
      "source": [
        "print(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a', 'able', 'access', 'activation', 'ada', 'adam', 'aifl', 'aiml', 'am', 'an', 'ann', 'anyone', 'are', 'artificial', 'backward', 'bad', 'bagging', 'batch', 'bayes', 'belong', 'best', 'blended', 'bloody', 'boosting', 'bot', 'buddy', 'classification', 'contact', 'create', 'cross', 'cya', 'day', 'deep', 'did', 'diffult', 'do', 'ensemble', 'epoch', 'explain', 'first', 'for', 'forest', 'forward', 'from', 'function', 'good', 'goodbye', 'gradient', 'great', 'hate', 'have', 'hell', 'hello', 'help', 'helped', 'hey', 'hi', 'hidden', 'hour', 'how', 'hyper', 'i', 'imputer', 'in', 'intelligence', 'is', 'jerk', 'joke', 'knn', 'later', 'layer', 'learner', 'learning', 'leaving', 'link', 'listen', 'logistic', 'lot', 'machine', 'me', 'ml', 'my', 'naive', 'name', 'nb', 'net', 'network', 'neural', 'no', 'not', 'of', 'olympus', 'olypus', 'on', 'online', 'operation', 'opertions', 'otimizer', 'parameter', 'piece', 'please', 'pm', 'problem', 'propagation', 'random', 'regression', 'relu', 'screw', 'see', 'sgd', 'shit', 'sigmoid', 'sl', 'smart', 'softmax', 'solution', 'solved', 'stupid', 'supervised', 'svm', 'talking', 'teach', 'techb=niques', 'technique', 'thank', 'thanks', 'the', 'there', 'think', 'ticket', 'time', 'to', 'ton', 'too', 'tool', 'unable', 'understand', 'up', 'use', 'useless', 'validation', 'very', 'visible', 'wasted', 'weight', 'what', 'whats', 'when', 'who', 'whom', 'window', 'with', 'work', 'working', 'ya', 'yo', 'you', 'your']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7WJLUCPjglH",
        "outputId": "5234f296-478f-4bc4-fc5f-f515d02ce4a6"
      },
      "source": [
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Bot', 'Exit', 'Intro', 'NN', 'Olympus', 'Profane', 'SL', 'Ticket']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiV5r4PUjgi_",
        "outputId": "20ecec64-1ffb-414e-88fe-5bf33458ad20"
      },
      "source": [
        "print(doc_x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['hi', 'how are you', 'is anyone there', 'hello', 'whats up', 'hey', 'yo', 'listen', 'please help me', 'i am learner from', 'i belong to', 'aiml batch', 'aifl batch', 'i am from', 'my pm is', 'blended', 'online', 'i am from', 'hey ya', 'talking to you for first time', 'thank you', 'thanks', 'cya', 'see you', 'later', 'see you later', 'goodbye', 'i am leaving', 'have a Good day', 'you helped me', 'thanks a lot', 'thanks a ton', 'you are the best', 'great help', 'too good', 'you are a good learning buddy', 'olympus', 'explain me how olympus works', 'I am not able to understand olympus', 'olympus window not working', 'no access to olympus', 'unable to see link in olympus', 'no link visible on olympus', 'whom to contact for olympus', 'lot of problem with olympus', 'olypus is not a good tool', 'lot of problems with olympus', 'how to use olympus', 'teach me olympus', 'i am not able to understand svm', 'explain me how machine learning works', 'i am not able to understand naive bayes', 'i am not able to understand logistic regression', 'i am not able to understand ensemble techb=niques', 'i am not able to understand knn', 'i am not able to understand knn imputer', 'i am not able to understand cross validation', 'i am not able to understand boosting', 'i am not able to understand random forest', 'i am not able to understand ada boosting', 'i am not able to understand gradient boosting', 'machine learning', 'ML', 'SL', 'supervised learning', 'knn', 'logistic regression', 'regression', 'classification', 'naive bayes', 'nb', 'ensemble techniques', 'bagging', 'boosting', 'ada boosting', 'ada', 'gradient boosting', 'hyper parameters', 'what is deep learning', 'unable to understand deep learning', 'explain me how deep learning works', 'i am not able to understand deep learning', 'not able to understand neural nets', 'very diffult to understand neural nets', 'unable to understand neural nets', 'ann', 'artificial intelligence', 'artificial neural networks', 'weights', 'activation function', 'hidden layers', 'softmax', 'sigmoid', 'relu', 'otimizer', 'forward propagation', 'backward propagation', 'epochs', 'epoch', 'what is an epoch', 'adam', 'sgd', 'what is your name', 'who are you', 'name please', 'when are your hours of opertions', 'what are your working hours', 'hours of operation', 'working hours', 'hours', 'what the hell', 'bloody stupid bot', 'do you think you are very smart', 'screw you', 'i hate you', 'you are stupid', 'jerk', 'you are a joke', 'useless piece of shit', 'my problem is not solved', 'you did not help me', 'not a good solution', 'bad solution', 'not good solution', 'no help', 'wasted my time', 'useless bot', 'create a ticket']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixNOQTjNjgaK",
        "outputId": "8b3d388f-bf72-456a-89a7-5b3bb380b0ea"
      },
      "source": [
        "print(doc_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'Bot', 'Bot', 'Bot', 'Bot', 'Bot', 'Bot', 'Bot', 'Bot', 'Profane', 'Profane', 'Profane', 'Profane', 'Profane', 'Profane', 'Profane', 'Profane', 'Profane', 'Ticket', 'Ticket', 'Ticket', 'Ticket', 'Ticket', 'Ticket', 'Ticket', 'Ticket', 'Ticket']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz7TUeNdjgYJ"
      },
      "source": [
        "# list for training data\n",
        "training = []\n",
        "out_empty = [0] * len(classes)\n",
        "\n",
        "# Creating the bag of words model\n",
        "for idx, doc in enumerate(doc_x):\n",
        "    bow = []\n",
        "    text = lem.lemmatize(doc.lower())\n",
        "    for word in words:\n",
        "        bow.append(1) if word in text else bow.append(0)\n",
        "\n",
        "    # Mark the index of class that the current pattern is associated to\n",
        "    output_row = list(out_empty)\n",
        "    output_row[classes.index(doc_y[idx])] = 1\n",
        "\n",
        "    # Add the one hot encoded BoW and associated classes to training \n",
        "    training.append([bow, output_row])\n",
        "\n",
        "# Shuffle the data and convert it to an array\n",
        "random.shuffle(training)\n",
        "training = np.array(training, dtype=object)\n",
        "\n",
        "# Split the features and target labels\n",
        "train_x = np.array(list(training[:, 0]))\n",
        "train_y = np.array(list(training[:, 1]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOJoyx_GjgSU"
      },
      "source": [
        "# defining some parameters\n",
        "input_shape = (len(train_x[0]),)\n",
        "output_shape = len(train_y[0])\n",
        "epochs = 200\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=input_shape, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(output_shape, activation = \"softmax\"))\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsKmrBxXrDKm",
        "outputId": "2b91213e-f957-4e8f-b5dd-69a0f429d7b6"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.summary()\n",
        "model.fit(x = train_x, y = train_y, epochs = 200, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               20352     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 520       \n",
            "=================================================================\n",
            "Total params: 29,128\n",
            "Trainable params: 29,128\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "4/4 [==============================] - 2s 5ms/step - loss: 2.0786 - accuracy: 0.1698\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.0912 - accuracy: 0.1323\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.0417 - accuracy: 0.1625\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.0339 - accuracy: 0.2510\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.9836 - accuracy: 0.2260\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.9368 - accuracy: 0.2708\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.9167 - accuracy: 0.3312\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.8923 - accuracy: 0.2927\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.9036 - accuracy: 0.3625\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.8250 - accuracy: 0.3438\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.7985 - accuracy: 0.3333\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.7832 - accuracy: 0.4042\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.7065 - accuracy: 0.4729\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.7738 - accuracy: 0.3740\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.6676 - accuracy: 0.4240\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.6295 - accuracy: 0.4885\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.5756 - accuracy: 0.5219\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.6206 - accuracy: 0.3906\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.5197 - accuracy: 0.4906\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.5232 - accuracy: 0.4865\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.4025 - accuracy: 0.5906\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.3670 - accuracy: 0.5990\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3846 - accuracy: 0.6510\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2718 - accuracy: 0.5844\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3111 - accuracy: 0.6146\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1786 - accuracy: 0.7094\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1419 - accuracy: 0.6885\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0926 - accuracy: 0.6813\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0781 - accuracy: 0.7208\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9749 - accuracy: 0.7885\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0389 - accuracy: 0.6969\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0487 - accuracy: 0.7135\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9530 - accuracy: 0.7229\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9502 - accuracy: 0.7792\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7854 - accuracy: 0.8510\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8023 - accuracy: 0.7885\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8577 - accuracy: 0.7635\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8045 - accuracy: 0.7865\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8039 - accuracy: 0.8385\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7094 - accuracy: 0.8448\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6602 - accuracy: 0.8719\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6484 - accuracy: 0.8510\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5830 - accuracy: 0.8604\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6205 - accuracy: 0.8375\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5789 - accuracy: 0.8750\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.8979\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.8917\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.9260\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4729 - accuracy: 0.9187\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.8938\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.8896\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.9375\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.9052\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3625 - accuracy: 0.9625\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3262 - accuracy: 0.9375\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3537 - accuracy: 0.9073\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3344 - accuracy: 0.9344\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3596 - accuracy: 0.9083\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2502 - accuracy: 0.9469\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2475 - accuracy: 0.9635\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2240 - accuracy: 0.9594\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2194 - accuracy: 0.9708\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2359 - accuracy: 0.9719\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2421 - accuracy: 0.9500\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2344 - accuracy: 0.9771\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2419 - accuracy: 0.9635\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2378 - accuracy: 0.9573\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1887 - accuracy: 0.9729\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2298 - accuracy: 0.9563\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1936 - accuracy: 0.9708\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1721 - accuracy: 0.9802\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1906 - accuracy: 0.9635\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1892 - accuracy: 0.9802\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1936 - accuracy: 0.9646\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1376 - accuracy: 0.9708\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1619 - accuracy: 0.9792\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1530 - accuracy: 0.9917\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1557 - accuracy: 0.9677\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1417 - accuracy: 0.9740\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1266 - accuracy: 0.9760\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1171 - accuracy: 0.9969\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1047 - accuracy: 0.9885\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1338 - accuracy: 0.9771\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1347 - accuracy: 0.9854\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1272 - accuracy: 0.9792\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1247 - accuracy: 0.9802\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1340 - accuracy: 0.9656\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1524 - accuracy: 0.9542\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9885\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1227 - accuracy: 0.9719\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0775 - accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.9938\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1177 - accuracy: 0.9854\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1514 - accuracy: 0.9333\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0954 - accuracy: 0.9823\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.9719\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1019 - accuracy: 0.9885\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0793 - accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9948\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9823\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0822 - accuracy: 0.9969\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0845 - accuracy: 0.9823\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0907 - accuracy: 0.9854\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0803 - accuracy: 0.9969\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0727 - accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9948\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9948\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0579 - accuracy: 0.9948\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0603 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0549 - accuracy: 0.9917\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.9802\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0664 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.9969\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.9854\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.9948\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9854\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0601 - accuracy: 0.9854\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.9854\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0348 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9708\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9969\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0469 - accuracy: 0.9917\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0298 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0276 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0438 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9969\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9948\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0301 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0351 - accuracy: 0.9917\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0367 - accuracy: 0.9948\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9885\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.9969\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0481 - accuracy: 0.9823\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9948\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0294 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0273 - accuracy: 0.9969\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0543 - accuracy: 0.9771\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.9948\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0320 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.9969\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0404 - accuracy: 0.9854\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0371 - accuracy: 0.9854\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 0.9948\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0238 - accuracy: 0.9917\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0367 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0301 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0314 - accuracy: 0.9969\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.9854\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 0.9917\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9854\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9948\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0141 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0440 - accuracy: 0.9854\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9948\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9771\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0277 - accuracy: 0.9917\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9969\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9948\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0144 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f49a60eded0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuMiLttXLyCE"
      },
      "source": [
        "def clean_text(text): \n",
        "  tokens = nltk.word_tokenize(text)\n",
        "  tokens = [lem.lemmatize(word) for word in tokens]\n",
        "  return tokens\n",
        "\n",
        "def bag_of_words(text, vocab): \n",
        "  tokens = clean_text(text)\n",
        "  bow = [0] * len(vocab)\n",
        "  for w in tokens: \n",
        "    for idx, word in enumerate(vocab):\n",
        "      if word == w: \n",
        "        bow[idx] = 1\n",
        "  return np.array(bow)\n",
        "\n",
        "def pred_class(text, vocab, labels): \n",
        "  bow = bag_of_words(text, vocab)\n",
        "  result = model.predict(np.array([bow]))[0]\n",
        "  thresh = 0.2\n",
        "  y_pred = [[idx, res] for idx, res in enumerate(result) if res > thresh]\n",
        "\n",
        "  y_pred.sort(key=lambda x: x[1], reverse=True)\n",
        "  return_list = []\n",
        "  for r in y_pred:\n",
        "    return_list.append(labels[r[0]])\n",
        "  return return_list\n",
        "\n",
        "def get_response(intents_list, intents_json): \n",
        "  tag = intents_list[0]\n",
        "  list_of_intents = intents_json[\"intents\"]\n",
        "  for i in list_of_intents: \n",
        "    if i[\"tag\"] == tag:\n",
        "      result = random.choice(i[\"responses\"])\n",
        "      break\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwR0XAR399Tg"
      },
      "source": [
        "# Running the chatbot\n",
        "\n",
        "while True:\n",
        "    message = input(\"\")\n",
        "    intents = pred_class(message, words, classes) \n",
        "    result = get_response(intents, Corpus)\n",
        "    print(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}